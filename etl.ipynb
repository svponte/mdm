{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tramento dos dados brutos\r\n",
    "\r\n",
    "Após a carga dos dataset a partir dos arquivos (doCarga), nesta etapa os dados sofrerão limpesa e tratamento, aonde serão retiradas \"sugeiras grosseiras\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def doETL():\r\n",
    "    stopwords = set(stopwords.words('portuguese') )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "listaRetiraInicio = [] # ['BB','Z ', 'MC ']\r\n",
    "listaRetiraFim    = [] # [' CC']\r\n",
    "listaCaracteresIndesejados = [\"\t\", # tabulação\r\n",
    "                              \"*\",\r\n",
    "                              \"#\",\r\n",
    "                              \"|\",\r\n",
    "                              '¥'\r\n",
    "                             ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# retira stop words do nome dos usuários reais\r\n",
    "def limpaTexto( entrada ):\r\n",
    "    \r\n",
    "    # PROBLEMA: TEM QUE VERIFICAR A LISTA DE STOPWORDS PARA QUE ELA \r\n",
    "    # NÃO RETIRE DESCRIÇÃO VÁLIDA DE PRODUTOS.\r\n",
    "    # retira stopwords\r\n",
    "    entrada = str(entrada)\r\n",
    "    entrada = entrada.split(\" \")\r\n",
    "    saida = \"\"\r\n",
    "    for item in entrada:\r\n",
    "        if item.lower() not in stopwords:\r\n",
    "            saida = saida + item + \" \"\r\n",
    "    \r\n",
    "    # retira acentos\r\n",
    "    aux   = str(saida)\r\n",
    "    nfkd  = unicodedata.normalize('NFKD', aux)\r\n",
    "    saida = u\"\".join([c for c in nfkd if not unicodedata.combining(c)])\r\n",
    "    \r\n",
    "    # transforma em maiúsculo, retira espaços dos extremos (TRIM), \r\n",
    "    saida = saida.upper().strip()\r\n",
    "    \r\n",
    "    # retira caracteres indesejados --> cuidado para não unir palavras separadas pelo caracter\r\n",
    "    for item in listaCaracteresIndesejados:\r\n",
    "        saida = saida.replace(item,\"\")    \r\n",
    "    \r\n",
    "    # retira espaços duplos dentro da string\r\n",
    "    saida = saida.replace(\"  \",\" \")\r\n",
    "    while saida.find('  ') != -1:\r\n",
    "        saida = saida.replace(\"  \",\" \")\r\n",
    "              \r\n",
    "    # retira inicios de strings que constam na lista listaRetiraInicio\r\n",
    "    for item in listaRetiraInicio:\r\n",
    "        # retira espaços duplos dentro do item, pois o mesmo já foi feito no texto a pesquisar\r\n",
    "        item = item.replace(\"  \",\" \")\r\n",
    "        while item.find('  ') != -1:\r\n",
    "            item = item.replace(\"  \",\" \")\r\n",
    "            \r\n",
    "        if saida.startswith(item):\r\n",
    "            tamanhoItem  = len(item)\r\n",
    "            tamanhoSaida = len(saida)            \r\n",
    "            if tamanhoSaida > tamanhoItem:\r\n",
    "                saida = saida[tamanhoItem:]\r\n",
    "    \r\n",
    "    # retira fins de strings que constam na lista listaRetiraFim\r\n",
    "    for item in listaRetiraFim:\r\n",
    "        # retira espaços duplos dentro do item, pois o mesmo já foi feito no texto a pesquisar\r\n",
    "        item = item.replace(\"  \",\" \")\r\n",
    "        while item.find('  ') != -1:\r\n",
    "            item = item.replace(\"  \",\" \")        \r\n",
    "        \r\n",
    "        if saida.endswith(item):\r\n",
    "            tamanhoItem  = len(item)\r\n",
    "            tamanhoSaida = len(saida)\r\n",
    "            if tamanhoSaida > tamanhoItem:\r\n",
    "                saida = saida[:tamanhoSaida-tamanhoItem]   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    # retira espaços duplos dentro da string. Necessário pois pode ter sobrado \r\n",
    "    # espaço depois das alterações\r\n",
    "    saida = saida.strip()\r\n",
    "        \r\n",
    "    return saida "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Somente para teste da rotina de limpa texto\r\n",
    "resp = limpaTexto('00000lf1412214')\r\n",
    "resp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Insere coluna \"NovaDescricao\" com as descrições tratadas \r\n",
    "novadescricao = map( limpaTexto, df_original['Desc_Catalogo'] ) \r\n",
    "df_original.insert( loc = 2, column = \"NovaDescricao\", value = list(novadescricao))#, allow_duplicates = False)\r\n",
    "del novadescricao"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Apaga linhas cuja coluna 'NovaDescricao' esteja em branco\r\n",
    "df_original['NovaDescricao'].dropna( axis=0, inplace=True )  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Concatena 3 colunas para formar a coluna 'Categoria', que é a classificação do produto\r\n",
    "df_original['Categoria'] = df_original['Item_Anexo_IV'].astype(str) + df_original['Prod_ST'] + df_original['Prod_FCP']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Apaga colunas que não serão usadas\r\n",
    "df_original.drop(['Desc_Catalogo', 'NCM_NFe', 'Desc_Anexo_IV', 'NCM_Calc_Prov', 'Cor_NCM_Calc', 'NCM_Calc', \r\n",
    "         'Item_Anexo_IV', 'Prod_ST', 'Prod_FCP'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Renomeia as colunas do DF\r\n",
    "df_original.columns = ('Remetente','NovaDescricao','Categoria')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elimina linhas inconsistentes, repetidas. Mantém a primeira delas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "antes = df_original.shape[0]\r\n",
    "df_original.drop_duplicates( subset = [\"NovaDescricao\"], inplace = True) \r\n",
    "print( 'Eliminados', antes - df_original.shape[0], 'registros')\r\n",
    "del antes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Retira categorias indesejadas\r\n",
    "retirar = ['nannãonão','nansimnão','nansimsim']\r\n",
    "mask = ~df_original['Categoria'].isin(retirar)\r\n",
    "filtrado = df_original[mask].copy()\r\n",
    "df_original = filtrado.copy()\r\n",
    "del filtrado, retirar"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Cria o DF com os dados obtidos da base a ser trabalhada, já ajustada. \r\n",
    "# O df_original fica com backup, durante o desenvolimento porque a base demora para ser lida.\r\n",
    "\r\n",
    "df = df_original.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CRIA LISTA DE PALAVRAS, COM CÁLCULO DO Nº DE REPETIÇÃO - INICIO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Gera lista com todas as palavras, com repetições\r\n",
    "# CountVectorizer retira duplicidade\r\n",
    "total_linhas = df.shape[0]\r\n",
    "lista_palavras = []\r\n",
    "for i in range(0,total_linhas):\r\n",
    "    texto = df.iloc[i, 1].split()\r\n",
    "    tamanho_linha = len(texto)\r\n",
    "    for j in range(0,tamanho_linha):\r\n",
    "        lista_palavras.append( texto[j]) \r\n",
    "        \r\n",
    "# Gera DF com a contagem de cada palavra\r\n",
    "lista_palavras = pd.Series(data = lista_palavras)\r\n",
    "df_lista_palavras = pd.DataFrame(data = lista_palavras.value_counts() )#, index = lista_palavras)\r\n",
    "df_lista_palavras.reset_index(drop = False, inplace = True)\r\n",
    "df_lista_palavras.columns = ['Palavra','QTD']\r\n",
    "\r\n",
    "#libera memoria\r\n",
    "del total_linhas, lista_palavras, texto, tamanho_linha,"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Lista_palavras_eliminar = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "########### elimina palavras de 1 caracter\r\n",
    "\r\n",
    "mask = (df_lista_palavras['Palavra'].str.len() == 1)\r\n",
    "df_aux = df_lista_palavras[mask]\r\n",
    "Lista_palavras_eliminar = Lista_palavras_eliminar + list(df_aux['Palavra'])\r\n",
    "mask = ~(df_lista_palavras['Palavra'].str.len() == 1)\r\n",
    "df_aux = df_lista_palavras[mask]\r\n",
    "df_lista_palavras = df_aux.copy()\r\n",
    "\r\n",
    "del df_aux, mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "########### elimina palavras que são somente numeros, exceto os de 13 algarismos ( possíveis EAN)\r\n",
    "\r\n",
    "# Separa possíveis códigos EAN\r\n",
    "mask1 = df_lista_palavras.Palavra.str.len() == 13\r\n",
    "mask2 = df_lista_palavras.Palavra.str.isdigit()\r\n",
    "df_aux = df_lista_palavras[~(mask1 & mask2)]\r\n",
    "# elimina números\r\n",
    "mask2 = df_aux.Palavra.str.isdigit()\r\n",
    "df_aux = df_aux[mask2]\r\n",
    "\r\n",
    "Lista_palavras_eliminar = Lista_palavras_eliminar + list(df_aux['Palavra'])\r\n",
    "mask = ~df_lista_palavras['Palavra'].isin( list(df_aux['Palavra']) )\r\n",
    "df_aux = df_lista_palavras[mask]\r\n",
    "df_lista_palavras = df_aux.copy()\r\n",
    "del df_aux, mask1, mask2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def EliminaPalavrasVindasDeArquivo( nome_arquivo ):\r\n",
    "    global Lista_palavras_eliminar\r\n",
    "    global df_lista_palavras\r\n",
    "    df_aux = pd.read_csv(nome_arquivo, index_col = ['Indice'], sep = ';',)\r\n",
    "    Lista_palavras_eliminar = Lista_palavras_eliminar + list(df_aux['Palavra'])\r\n",
    "    mask = ~df_lista_palavras['Palavra'].isin( list(df_aux['Palavra']) )\r\n",
    "    df_aux = df_lista_palavras[mask]\r\n",
    "    df_lista_palavras = df_aux.copy()\r\n",
    "    del df_aux, mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trata palavras terminadas com ML (mililitros) - INICIO "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ask1  = df_lista_palavras['Palavra'].str.endswith('ML')\r\n",
    "mask2  = df_lista_palavras['Palavra'].str.len() < 80\r\n",
    "mask3  = df_lista_palavras['QTD'] > 10 \r\n",
    "df_aux = df_lista_palavras[ mask1 & mask2 & mask3 ]\r\n",
    "\r\n",
    "df_aux.to_csv(\"ETL_ML_a_verificar.csv\", index = True, columns = [\"Palavra\", \"QTD\"], sep = ';', encoding = \"utf-8\")\r\n",
    "del df_aux, mask1, mask2, mask3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SOMENTE EXECUTE ESTA CELULA DEPOIS DE VERIFICAR MANUALMENTE O ARQUIVO\r\n",
    "\r\n",
    "EliminaPalavrasVindasDeArquivo( \"ETL_ML_verificado.csv\" )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trata palavras pela quantidade delas - INICIO "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask  = df_lista_palavras['QTD'] > 1000 \r\n",
    "df_aux = df_lista_palavras[ mask ]\r\n",
    "\r\n",
    "df_aux.to_csv(\"ETL_QUANTIDADE_a_verificar.csv\", index = True, columns = [\"Palavra\", \"QTD\"], sep = ';', encoding = \"utf-8\")\r\n",
    "del df_aux, mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SOMENTE EXECUTE ESTA CELULAR DEPOIS DE VERIFICAR MANUALMENTE O ARQUIVO\r\n",
    "\r\n",
    "EliminaPalavrasVindasDeArquivo( \"ETL_QUANTIDADE_verificado.csv\" )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trata palavras terminadas com KG  - INICIO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask1  = df_lista_palavras['Palavra'].str.endswith('KG')\r\n",
    "mask2  = df_lista_palavras['Palavra'].str.len() < 80\r\n",
    "mask3  = df_lista_palavras['QTD'] > 10 \r\n",
    "df_aux = df_lista_palavras[ mask1 & mask2 & mask3 ]\r\n",
    "\r\n",
    "df_aux.to_csv(\"ETL_KG_a_verificar.csv\", index = True, columns = [\"Palavra\", \"QTD\"], sep = ';', encoding = \"utf-8\")\r\n",
    "del df_aux, mask1, mask2, mask3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SOMENTE EXECUTE ESTA CELULAR DEPOIS DE VERIFICAR MANUALMENTE O ARQUIVO\r\n",
    "\r\n",
    "EliminaPalavrasVindasDeArquivo( \"ETL_KG_verificado.csv\" )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trata palavras terminadas com GR  - INICIO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask1  = df_lista_palavras['Palavra'].str.endswith('GR')\r\n",
    "mask2  = df_lista_palavras['Palavra'].str.len() < 80\r\n",
    "mask3  = df_lista_palavras['QTD'] > 10 \r\n",
    "df_aux = df_lista_palavras[ mask1 & mask2 & mask3 ]\r\n",
    "\r\n",
    "df_aux.to_csv(\"ETL_GR_a_verificar.csv\", index = True, columns = [\"Palavra\", \"QTD\"], sep = ';', encoding = \"utf-8\")\r\n",
    "del df_aux, mask1, mask2, mask3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SOMENTE EXECUTE ESTA CELULAR DEPOIS DE VERIFICAR MANUALMENTE O ARQUIVO\r\n",
    "\r\n",
    "EliminaPalavrasVindasDeArquivo( \"ETL_GR_verificado.csv\" )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trata palavras terminadas com GRAMAS  - INICIO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask1  = df_lista_palavras['Palavra'].str.endswith('GRAMAS')\r\n",
    "mask2  = df_lista_palavras['Palavra'].str.len() < 80\r\n",
    "mask3  = df_lista_palavras['QTD'] > 10 \r\n",
    "df_aux = df_lista_palavras[ mask1 & mask2 & mask3 ]\r\n",
    "\r\n",
    "if df_aux.shape[0] > 1:\r\n",
    "    df_aux.to_csv(\"ETL_GRAMAS_a_verificar.csv\", index = True, columns = [\"Palavra\", \"QTD\"], sep = ';', encoding = \"utf-8\")\r\n",
    "else:\r\n",
    "    print( 'Não há palavras terminadas com esta opcao, ou há somente uma.' )\r\n",
    "del df_aux, mask1, mask2, mask3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SOMENTE EXECUTE ESTA CELULAR DEPOIS DE VERIFICAR MANUALMENTE O ARQUIVO.\r\n",
    "\r\n",
    "#EliminaPalavrasVindasDeArquivo( \"ETL_GRAMAS_verificado.csv\" )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trata palavras terminadas com GRAMA  - INICIO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask1  = df_lista_palavras['Palavra'].str.endswith('GRAMA')\r\n",
    "mask2  = df_lista_palavras['Palavra'].str.len() < 80\r\n",
    "mask3  = df_lista_palavras['QTD'] > 10 \r\n",
    "df_aux = df_lista_palavras[ mask1 & mask2 & mask3 ]\r\n",
    "\r\n",
    "if df_aux.shape[0] > 1:\r\n",
    "    df_aux.to_csv(\"ETL_GRAMA_a_verificar.csv\", index = True, columns = [\"Palavra\", \"QTD\"], sep = ';', encoding = \"utf-8\")\r\n",
    "else:\r\n",
    "    print( 'Não há palavras terminadas com esta opcao, ou há somente uma.' )\r\n",
    "del df_aux, mask1, mask2, mask3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SOMENTE EXECUTE ESTA CELULAR DEPOIS DE VERIFICAR MANUALMENTE O ARQUIVO\r\n",
    "\r\n",
    "#EliminaPalavrasVindasDeArquivo( \"ETL_GRAMA_verificado.csv\" )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trata palavras terminadas com G  - INICIO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask1  = df_lista_palavras['Palavra'].str.endswith('G')\r\n",
    "mask2  = df_lista_palavras['Palavra'].str.len() < 80\r\n",
    "mask3  = df_lista_palavras['QTD'] > 10 \r\n",
    "df_aux = df_lista_palavras[ mask1 & mask2 & mask3 ]\r\n",
    "\r\n",
    "if df_aux.shape[0] > 1:\r\n",
    "    df_aux.to_csv(\"ETL_G_a_verificar.csv\", index = True, columns = [\"Palavra\", \"QTD\"], sep = ';', encoding = \"utf-8\")\r\n",
    "else:\r\n",
    "    print( 'Não há palavras terminadas com esta opcao, ou há somente uma.' )\r\n",
    "del df_aux, mask1, mask2, mask3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SOMENTE EXECUTE ESTA CELULAR DEPOIS DE VERIFICAR MANUALMENTE O ARQUIVO\r\n",
    "\r\n",
    "EliminaPalavrasVindasDeArquivo( \"ETL_G_verificado.csv\" )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Salva dados - inicio"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Salva as palavras da base, já com as devidas retiradas de palavras\r\n",
    "df_lista_palavras.to_csv(\"ETL_base_lista_palavras_corretas.csv\", index = True, \r\n",
    "                         columns = [\"Palavra\", \"QTD\"], sep = ';', encoding = \"utf-8\")\r\n",
    "\r\n",
    "df_lista_palavras.to_pickle(\"./ETL_base_lista_palavras_corretas.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elimina palavras indesejadas - INICIO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "palavraPermitida = df_lista_palavras['Palavra']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dicPermitido = dict(zip(palavraPermitida, palavraPermitida))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def verificaDescricao(frase):\r\n",
    "    global dicPermitido\r\n",
    "    \r\n",
    "    resp = ''\r\n",
    "    frase = frase.split(\" \")\r\n",
    "    for palavra in frase:\r\n",
    "        resp = resp + \" \" + dicPermitido.get(palavra,'')\r\n",
    "    resp = resp.strip()\r\n",
    "    resp = resp.replace(\"  \",\" \")\r\n",
    "    return resp    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aux = list( map(lambda x: verificaDescricao(x), list(df_original['NovaDescricao']) ) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_original['NovaDescricao'] = aux"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_original.to_pickle(\"./ETL_base_pronta_para_previsao.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_original['Categoria'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}