{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mineração de Dados Massivos\r\n",
    "## Analise de descrição de mercadorias de Notas Fiscais Eletrônicas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bibliotecas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Iniciando Ambiente\r\n",
    "import numpy as np, pandas as pd, time, random\r\n",
    "import datetime as dt\r\n",
    "\r\n",
    "import nltk\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import unicodedata\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import warnings\r\n",
    "from pylab import rcParams\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import precision_score, recall_score\r\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\r\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\r\n",
    "\r\n",
    "# Se necessário, descomente as linhas a seguir para ler as stopwords\r\n",
    "nltk.download('stopwords')\r\n",
    "nltk.download('rslp')\r\n",
    "stemmer = nltk.stem.RSLPStemmer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Módulos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Módulos de código de programação\r\n",
    "#!pip install import-ipynb\r\n",
    "import import_ipynb\r\n",
    "\r\n",
    "# Carga de Arquivos\r\n",
    "from carga import doCarga\r\n",
    "\r\n",
    "# Tratamento de Dados         \r\n",
    "from tratamento import doTratamento\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variáveis de Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Pasta aonde estão os dados\r\n",
    "diretorio = '..\\\\dados\\\\'\r\n",
    "#diretorio = \"F:\\\\Weisner\\\\Documentos\\\\MEGA Estudos\\\\UNB - MDM - Mineração de Dados Massivos\\\\Artigo\\\\\" \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Contador de tempo\r\n",
    "def tic():\r\n",
    "    global _start_time \r\n",
    "    _start_time = time.time()\r\n",
    "\r\n",
    "def tac():\r\n",
    "    t_sec = round(time.time() - _start_time)\r\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\r\n",
    "    (t_hour,t_min) = divmod(t_min,60) \r\n",
    "    print('Duração: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Carga dos dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Abrir arquivo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Carrega os dados\r\n",
    "dfNotas = doCarga(diretorio, opcao=3)\r\n",
    "print (\"{} registros carregados\".format(dfNotas.size))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processa se necessário"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# doTratamento(dfNotas, diretorio)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Amostra dos dados\r\n",
    "dfNotas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove a coluna de Remetente\r\n",
    "dfNotas = dfNotas.drop(columns=['Remetente'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Balanceamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Situação - AS-IS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.set(font_scale=1.4)\r\n",
    "dfNotas['Categoria'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\r\n",
    "plt.xlabel(\"Categorias\", labelpad=14)\r\n",
    "plt.ylabel(\"Registros\", labelpad=14)\r\n",
    "plt.title(\"Quantidade de categorias por registro\", y=1.02);\r\n",
    "\r\n",
    "plt.savefig('imagens/DisDesbalanceada.png', bbox_inches='tight');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfNotas['Categoria'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Separa os contadores\r\n",
    "count_class_0, count_class_1, count_class_2, count_class_3, count_class_4, count_class_5, count_class_6, count_class_7, count_class_8, count_class_9, count_class_10, count_class_11, count_class_12, count_class_13, count_class_14 = dfNotas['Categoria'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Divide datasets por classes\r\n",
    "df_class_0 = dfNotas[dfNotas['Categoria'] == \"41.0simnão\"]\r\n",
    "df_class_1 = dfNotas[dfNotas['Categoria'] == \"40.0simnão\"]\r\n",
    "df_class_2 = dfNotas[dfNotas['Categoria'] == \"38.0simnão\"]\r\n",
    "df_class_3 = dfNotas[dfNotas['Categoria'] == \"42.0simnão\"]\r\n",
    "df_class_4 = dfNotas[dfNotas['Categoria'] == \"31.0simsim\"]\r\n",
    "df_class_5 = dfNotas[dfNotas['Categoria'] == \"38.0simsim\"]\r\n",
    "df_class_6 = dfNotas[dfNotas['Categoria'] == \"40.0nãonão\"]\r\n",
    "df_class_7 = dfNotas[dfNotas['Categoria'] == \"38.0nãonão\"]\r\n",
    "df_class_8 = dfNotas[dfNotas['Categoria'] == \"39.0simnão\"]\r\n",
    "df_class_9 = dfNotas[dfNotas['Categoria'] == \"41.0nãonão\"]\r\n",
    "df_class_10 = dfNotas[dfNotas['Categoria'] == \"39.0nãonão\"]\r\n",
    "df_class_11 = dfNotas[dfNotas['Categoria'] == \"42.0nãonão\"]\r\n",
    "df_class_12 = dfNotas[dfNotas['Categoria'] == \"30.0simsim\"] # Tamanho escolhido\r\n",
    "df_class_13 = dfNotas[dfNotas['Categoria'] == \"31.0nãonão\"] # 182 - poucos registros\r\n",
    "df_class_14 = dfNotas[dfNotas['Categoria'] == \"30.0nãonão\"] # 9 - insignificante\r\n",
    "\r\n",
    "# Equipara os tamanhos 30.0simsim\r\n",
    "# Foram equiparados ao tamanho da classe 3\r\n",
    "#MaxSize = df_class_3.size \r\n",
    "#MaxSize = 3000 # df_class_3.size \r\n",
    "#MaxSize = 2500 # df_class_3.size "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Undersampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Faz o undersampling a partir de amostras aleatórias\r\n",
    "df_class_0 = df_class_0.sample(MaxSize)\r\n",
    "df_class_1 = df_class_1.sample(MaxSize)\r\n",
    "df_class_2 = df_class_2.sample(MaxSize)\r\n",
    "df_class_3 = df_class_3.sample(MaxSize)\r\n",
    "df_class_4 = df_class_4.sample(MaxSize)\r\n",
    "df_class_5 = df_class_5.sample(MaxSize)\r\n",
    "df_class_6 = df_class_6.sample(MaxSize)\r\n",
    "df_class_7 = df_class_7.sample(MaxSize)\r\n",
    "df_class_8 = df_class_8.sample(MaxSize)\r\n",
    "df_class_9 = df_class_9.sample(MaxSize)\r\n",
    "df_class_10 = df_class_10.sample(MaxSize)\r\n",
    "df_class_11 = df_class_11.sample(MaxSize)\r\n",
    "df_class_12 = df_class_12.sample(MaxSize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Oversampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Oversampling\r\n",
    "df_class_13 = df_class_13.sample(MaxSize, replace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reagrupa"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Agrupa novamente\r\n",
    "dfAjustado = pd.concat([df_class_0, df_class_1, df_class_2, df_class_3, df_class_4, df_class_5, df_class_6, df_class_7, df_class_8, df_class_9, df_class_10, df_class_11, df_class_12, df_class_13], axis=0)\r\n",
    "dfAjustado = dfAjustado.sample(frac = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfAjustado"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resultado - Dataset Balanceado"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Gera imagem do balanceamento ajustado\r\n",
    "sns.set(font_scale=1.4)\r\n",
    "dfAjustado['Categoria'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\r\n",
    "plt.xlabel(\"Categorias\", labelpad=14)\r\n",
    "plt.ylabel(\"Registros\", labelpad=14)\r\n",
    "plt.title(\"Quantidade de categorias por registro\", y=1.02);\r\n",
    "plt.savefig('imagens/DisBalanceada.png', bbox_inches='tight');  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfAjustado.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfAjustado = dfAjustado.sample(frac=1).reset_index(drop=True)\r\n",
    "dfAjustado = dfAjustado[['Categoria', 'NovaDescricao']]\r\n",
    "\r\n",
    "base_treino = dfAjustado.iloc[:20000,:]\r\n",
    "base_teste = dfAjustado.iloc[20001:,:]\r\n",
    "\r\n",
    "#exemplo_base_treino.Categoria.value_counts()\r\n",
    "base_teste.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preleção"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## StopWords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Função para retirar as StopWords do Corpus\r\n",
    "def removeStopWords(texto, lista_Stop):\r\n",
    "    frases = []\r\n",
    "    for (palavras, categoria) in texto:\r\n",
    "        # List Comprehension para pegar palavras fora do lista_Stop\r\n",
    "        semStop = [ p for p in palavras.split() if p not in lista_Stop]\r\n",
    "        frases.append((semStop, categoria))\r\n",
    "    return frases"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# StopWords já contempladas na biblioteca NLTK\r\n",
    "lista_Stop = nltk.corpus.stopwords.words('portuguese')\r\n",
    "#np.transpose(lista_Stop)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Adicionar StopWord customizada\r\n",
    "#lista_Stop.append('Palavra_adicionar')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stemming"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remover sufixos e prefixos das palavras\r\n",
    "def aplica_Stemmer(texto):\r\n",
    "    global nltk\r\n",
    "    global lista_Stop\r\n",
    "    nltk.download('rslp')\r\n",
    "    stemmer = nltk.stem.RSLPStemmer()\r\n",
    "    frases_sem_Stemming = []\r\n",
    "    for ( Categoria, NovaDescricao) in texto:\r\n",
    "        com_Stemming = [str(stemmer.stem(p)) for p in NovaDescricao.split() if p not in lista_Stop]\r\n",
    "        frases_sem_Stemming.append((com_Stemming, Categoria))\r\n",
    "    return frases_sem_Stemming"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Aplicat o Steeming na base de treino\r\n",
    "frases_com_Stem_treinamento = aplica_Stemmer(base_treino.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(frases_com_Stem_treinamento, columns=['Produto', 'Categoria']).sample(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Aplica o Steaming na base de testes\r\n",
    "frases_com_Stem_teste = aplica_Stemmer(base_teste.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Análise dos dados de entrada"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Função para retornar apenas as palavras, sem a classificação (categoria)\r\n",
    "def busca_Palavras(frases):\r\n",
    "    todas_Palavras = []\r\n",
    "    for (palavras, Categoria) in frases:\r\n",
    "        todas_Palavras.extend(palavras)\r\n",
    "    return todas_Palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Função para verificar a quantidade de vezes que a palavra é mencionada\r\n",
    "def busca_frequencia(palavras):\r\n",
    "    global nltk\r\n",
    "    palavras = nltk.FreqDist(palavras)\r\n",
    "    return palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "palavras_treinamento = busca_Palavras(frases_com_Stem_treinamento)\r\n",
    "palavras_teste = busca_Palavras(frases_com_Stem_teste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print ('Quantidade de palavras no treinamento {}'.format(pd.DataFrame(palavras_treinamento).count()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "frequencia_treinamento = busca_frequencia(palavras_treinamento)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Função para retornar somente as palavras únicas\r\n",
    "def busca_palavras_unicas(frequencia):\r\n",
    "    freq = frequencia.keys()\r\n",
    "    return freq"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Função para identificar quais palavras únicas estão no documento passo para função\r\n",
    "def extrator_palavras(documento):\r\n",
    "    global palavras_unicas_treinamento\r\n",
    "    doc = set(documento)\r\n",
    "    caracteristicas = {}\r\n",
    "    for palavras in palavras_unicas_treinamento:\r\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\r\n",
    "    return caracteristicas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Mesmo anterior, só que dedicada para teste\r\n",
    "def extrator_palavras_teste(documento):\r\n",
    "    global palavras_unicas_teste\r\n",
    "    doc = set(documento)\r\n",
    "    caracteristicas = {}\r\n",
    "    for palavras in palavras_unicas_teste:\r\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\r\n",
    "    return caracteristicas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualizar quais palavras ocorrem com maior frequência\r\n",
    "# Pode ajudar a tunnar a stopwords\r\n",
    "frequencia_treinamento.most_common(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Ajustando treinamento\r\n",
    "frequencia_teste = busca_frequencia(palavras_teste)\r\n",
    "\r\n",
    "palavras_unicas_treinamento = busca_palavras_unicas(frequencia_treinamento)\r\n",
    "palavras_unicas_teste = busca_palavras_unicas(frequencia_teste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Faz o preenchimento se tem ou não a característica de acordo com parâmetro\r\n",
    "base_completa_treinamento = nltk.classify.apply_features(extrator_palavras, frases_com_Stem_treinamento)\r\n",
    "base_completa_teste = nltk.classify.apply_features(extrator_palavras_teste, frases_com_Stem_teste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MaxentClassifier\r\n",
    "tic()\r\n",
    "Acuracia_MC = 0\r\n",
    "MC_classifier = nltk.MaxentClassifier.train(base_completa_treinamento)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Acuracia_MC = nltk.classify.accuracy(MC_classifier, base_completa_teste)\r\n",
    "tac()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Acuracia_MC"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}