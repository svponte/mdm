{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mineração de Dados Massivos\r\n",
    "## Analise de descrição de mercadorias de Notas Fiscais Eletrônicas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bibliotecas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Iniciando Ambiente\r\n",
    "import numpy as np, pandas as pd, time, random\r\n",
    "import datetime as dt\r\n",
    "import re \r\n",
    "\r\n",
    "\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import nltk\r\n",
    "import unicodedata\r\n",
    "\r\n",
    "# Se necessário, descomente as linhas a seguir para ler as stopwords\r\n",
    "nltk.download('stopwords')\r\n",
    "\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\svpon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Módulos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Módulos de código de programação\r\n",
    "#!pip install import-ipynb\r\n",
    "import import_ipynb\r\n",
    "from carga import *\r\n",
    "from tratamento import *"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\svpon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from carga.ipynb\n",
      "importing Jupyter notebook from tratamento.ipynb\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<string>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fee44f9a22ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcarga\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtratamento\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\import_ipynb.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;31m# run the code in themodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\PPCA\\MDM\\git\\tratamento.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mc:\\PPCA\\MDM\\git\\carga.ipynb\u001b[0m in \u001b[0;36mdoCarga\u001b[1;34m(diretorio, opcao, arquivoXLS)\u001b[0m\n",
      "\u001b[1;32mc:\\PPCA\\MDM\\git\\carga.ipynb\u001b[0m in \u001b[0;36mdoFornecedorHide\u001b[1;34m(Origem)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1001\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[0;32m   3471\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3472\u001b[0m                     \u001b[1;31m# otherwise, either self or ref has swapped in new arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3473\u001b[1;33m                     \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3474\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m                     \u001b[1;31m# GH#33675 we have swapped in a new array, so parent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   3429\u001b[0m         \"\"\"\n\u001b[0;32m   3430\u001b[0m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3431\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3433\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miset\u001b[1;34m(self, loc, value)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[1;31m# Accessing public blknos ensures the public versions are initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m         \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[0munfit_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Contador de tempo\r\n",
    "def tic():\r\n",
    "    global _start_time \r\n",
    "    _start_time = time.time()\r\n",
    "\r\n",
    "def tac():\r\n",
    "    t_sec = round(time.time() - _start_time)\r\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\r\n",
    "    (t_hour,t_min) = divmod(t_min,60) \r\n",
    "    print('Duração: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variáveis de Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Pasta aonde estão os dados\r\n",
    "diretorio = '..\\\\dados\\\\'\r\n",
    "#diretorio = \"F:\\\\Weisner\\\\Documentos\\\\MEGA Estudos\\\\UNB - MDM - Mineração de Dados Massivos\\\\Artigo\\\\\" \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Abre arquivo de dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Carrega os dados\r\n",
    "df_original = doCarga(diretorio, opcao=2)\r\n",
    "print (\"{} registros carregados\".format(df_original.size))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10153810 registros carregados\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "## SANDBOX\r\n",
    "tic()\r\n",
    "df_original = doTratamento(df_original)\r\n",
    "df_original.NovaDescricao\r\n",
    "tac()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time passed: 0hour:0min:1sec\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepração dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "%matplotlib inline\r\n",
    "df_original['Categoria'].value_counts().plot.bar()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Categoria'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Categoria'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b7cff445ddd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_original\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Categoria'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Categoria'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "##from sklearn.datasets import fetch_20newsgroups\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn import metrics\r\n",
    "\r\n",
    "import sklearn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Função para avaliação dos modelos\r\n",
    "\r\n",
    "def avalia_modelo(clf, X, y):\r\n",
    "    resultados = sklearn.model_selection.cross_val_predict(clf, X, y, cv=5)\r\n",
    "    # print( pd.crosstab(y, resultados, rownames=['Real'], colnames=['Predito'], margins=True))\r\n",
    "    return np.mean(sklearn.model_selection.cross_val_score(clf, X, y, cv=5))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Obtem lista de fornecedores com mais de 10000 itens\r\n",
    "fornecedores = df['Remetente'].value_counts()\r\n",
    "mask = fornecedores > 10000\r\n",
    "fornecedores = list(fornecedores[mask].index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len( fornecedores )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_resultado     = [ [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan ] ]\r\n",
    "for i in range( len( fornecedores ) ):\r\n",
    "    df_resultado.append( [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan ] )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fornecedores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df_original.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cria o df de resultados\r\n",
    "colunas = [ 'Remetente','registros1','precisao1','registros2','precisao2','registros3','precisao3','registros4','precisao4' ]\r\n",
    "#df_resultado = [] #pd.DataFrame(columns = colunas)\r\n",
    "\r\n",
    "for fonteDados in range(0,2):\r\n",
    "    # fonteDados = 0 --> dados com as palavras separadas manualmente\r\n",
    "    # fonteDados = 1 --> dados sem as palavras separadas manualmente\r\n",
    "    \r\n",
    "    linha  = 0\r\n",
    "    coluna = 0\r\n",
    "\r\n",
    "    # retira as palavras separadas manualmente\r\n",
    "#    if fonteDados == 10:\r\n",
    "#        print( )\r\n",
    "#        print('Sem palavras selecionadas manualemnte.')\r\n",
    "#        print()\r\n",
    "#        \r\n",
    "#        # Lê o arquivo de paravras indesejadas \r\n",
    "#        df_palavras_a_eliminar = pd.read_csv('ETL_base_lista_palavras_a_retirar_minusculas.csv', sep=\";\")\r\n",
    "#        from nltk.corpus import stopwords\r\n",
    "#        stopwords = set( stopwords.words('portuguese') + list( df_palavras_a_eliminar['palavra'] ) )\r\n",
    "#\r\n",
    "#        # retira as palavras indesejadas do df\r\n",
    "#        novadescricao = map( limpaTexto2, df['NovaDescricao'] ) \r\n",
    "#        df.insert( loc = 2, column = \"NovaDescricao2\", value = list(novadescricao))#, allow_duplicates = False)\r\n",
    "#        del novadescricao \r\n",
    "#        del df['NovaDescricao']\r\n",
    "#        df.columns = ['Remetente', 'NovaDescricao', 'Categoria']  \r\n",
    "        \r\n",
    "#        linha  = 0\r\n",
    "#        coluna = 4\r\n",
    "        \r\n",
    "    # Cria um Pipeline - Classificador Composto\r\n",
    "    # vectorizer => transformer => classifier \r\n",
    "    text_clf = Pipeline([('counts' , CountVectorizer() ),\r\n",
    "                       #  ('tfidf', TfidfTransformer()),\r\n",
    "                         ('classifier'  , MultinomialNB()   ),\r\n",
    "                        ])\r\n",
    "    \r\n",
    "    # registra resultados\r\n",
    "    df_resultado[linha][          0] = 'Todos'\r\n",
    "    df_resultado[linha][ coluna + 1] = df.shape[0]\r\n",
    "    df_resultado[linha][ coluna + 2] = avalia_modelo(text_clf, df['NovaDescricao'], df['Categoria'])\r\n",
    "    \r\n",
    "    print(linha,' : ',coluna+1)\r\n",
    "    print( df_resultado[linha][          0] )\r\n",
    "    print( df_resultado[linha][ coluna + 1] )\r\n",
    "    print( df_resultado[linha][ coluna + 2] )\r\n",
    "    print()\r\n",
    "    \r\n",
    "    # Cria um Pipeline - Classificador Composto\r\n",
    "    # vectorizer => transformer => classifier \r\n",
    "    text_clf = Pipeline([('counts' , CountVectorizer() ),\r\n",
    "                         ('tfidf', TfidfTransformer()),\r\n",
    "                         ('classifier'  , MultinomialNB()   ),\r\n",
    "                        ])\r\n",
    "    \r\n",
    "    # registra resultados\r\n",
    "    df_resultado[linha][ coluna + 3] = df.shape[0]\r\n",
    "    df_resultado[linha][ coluna + 4] = avalia_modelo(text_clf, df['NovaDescricao'], df['Categoria'])    \r\n",
    "    \r\n",
    "    print(linha,' : ',coluna+3)\r\n",
    "    print( df_resultado[linha][          0] )\r\n",
    "    print( df_resultado[linha][ coluna + 3] )\r\n",
    "    print( df_resultado[linha][ coluna + 4] )\r\n",
    "    print()\r\n",
    "    \r\n",
    "    # calcula precisão para fornecedores\r\n",
    "    for fornecedor in fornecedores:\r\n",
    "        \r\n",
    "        linha += 1\r\n",
    "        \r\n",
    "        # obtem dados do fornecedor\r\n",
    "        mask = df[\"Remetente\"] == fornecedor\r\n",
    "        dados_fornecedor = df[ mask ]\r\n",
    "   \r\n",
    "\r\n",
    "        # Cria um Pipeline - Classificador Composto\r\n",
    "        # vectorizer => transformer => classifier \r\n",
    "        text_clf = Pipeline([('counts' , CountVectorizer() ),\r\n",
    "                           #  ('tfidf', TfidfTransformer()),\r\n",
    "                             ('classifier'  , MultinomialNB()   ),\r\n",
    "                            ])\r\n",
    "\r\n",
    "        # registra resultados\r\n",
    "        df_resultado[linha][          0] = fornecedor\r\n",
    "        df_resultado[linha][ coluna + 1] = dados_fornecedor.shape[0]\r\n",
    "        df_resultado[linha][ coluna + 2] = avalia_modelo(text_clf, dados_fornecedor['NovaDescricao'], \r\n",
    "                                                                   dados_fornecedor['Categoria'])\r\n",
    "        print(linha,' : ',coluna+1)\r\n",
    "        print( df_resultado[linha][          0] )\r\n",
    "        print( df_resultado[linha][ coluna + 1] )\r\n",
    "        print( df_resultado[linha][ coluna + 2] )\r\n",
    "        print()\r\n",
    "    \r\n",
    "        # Cria um Pipeline - Classificador Composto\r\n",
    "        # vectorizer => transformer => classifier \r\n",
    "        text_clf = Pipeline([('counts' , CountVectorizer() ),\r\n",
    "                             ('tfidf', TfidfTransformer()),\r\n",
    "                             ('classifier'  , MultinomialNB()   ),\r\n",
    "                            ])\r\n",
    "\r\n",
    "        # registra resultados\r\n",
    "        df_resultado[linha][ coluna + 3] = dados_fornecedor.shape[0]\r\n",
    "        df_resultado[linha][ coluna + 4] = avalia_modelo(text_clf, dados_fornecedor['NovaDescricao'], \r\n",
    "                                                                   dados_fornecedor['Categoria'])         \r\n",
    "        print(linha,' : ',coluna+3)\r\n",
    "        print( df_resultado[linha][          0] )\r\n",
    "        print( df_resultado[linha][ coluna + 3] )\r\n",
    "        print( df_resultado[linha][ coluna + 4] )\r\n",
    "        print()\r\n",
    "    \r\n",
    "    \r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_resultado"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create the transform\r\n",
    "vectorizer = CountVectorizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "text = df['NovaDescricao']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# tokenize and build vocab\r\n",
    "vectorizer.fit(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# summarize\r\n",
    "print(vectorizer.vocabulary_)\r\n",
    "# encode document\r\n",
    "vector = vectorizer.transform(text)\r\n",
    "# summarize encoded vector\r\n",
    "print(vector.shape)\r\n",
    "print(type(vector))\r\n",
    "print(vector.toarray())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(vectorizer.vocabulary_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(vectorizer.vocabulary_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "palavras = list(vectorizer.vocabulary_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "palavras.sort()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(palavras)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_palavras = pd.DataFrame(data = palavras)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_palavras.to_csv('palavras.cvs', sep=\";\", index=False )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pwd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vocabulário = list( vectorizer.vocabulary_ )\r\n",
    "vocabulário"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vocabulário.sort()\r\n",
    "vocabulário"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mineração"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}