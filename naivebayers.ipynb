{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "##from sklearn.datasets import fetch_20newsgroups\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn import metrics\r\n",
    "\r\n",
    "import sklearn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Função para avaliação dos modelos\r\n",
    "def avalia_modelo(clf, X, y):\r\n",
    "    resultados = sklearn.model_selection.cross_val_predict(clf, X, y, cv=5)\r\n",
    "    # print( pd.crosstab(y, resultados, rownames=['Real'], colnames=['Predito'], margins=True))\r\n",
    "    return np.mean(sklearn.model_selection.cross_val_score(clf, X, y, cv=5))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def doIniciaResult(tamanho):\r\n",
    "    # Iniciar um array com vazios\r\n",
    "    df_resultado     = [ [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan ] ]\r\n",
    "    for i in range( tamanho ):\r\n",
    "        df_resultado.append( [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan ] )\r\n",
    "\r\n",
    "    #df_resultado = [] #pd.DataFrame(columns = colunas)\r\n",
    "    colunas = [ 'Remetente','registros1','precisao1','registros2','precisao2','registros3','precisao3','registros4','precisao4' ]\r\n",
    "    return df_resultado"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def doFornecedorCut(dtNotas, fornecedores, tamanho = 1000):\r\n",
    "    # Obtem lista de fornecedores com mais de 10000 itens\r\n",
    "    fornecedores = dtNotas['Remetente'].value_counts()\r\n",
    "    mask = fornecedores > tamanho\r\n",
    "    fornecedores = list(fornecedores[mask].index)\r\n",
    "    return fornecedores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Processa o Naives\r\n",
    "def doProcNaives(dfNFiscais, fornecedores):\r\n",
    "  \r\n",
    "\t# Iniciar o Resutlado\r\n",
    "\tdf_resultado = doIniciaResult(len( fornecedores ))\r\n",
    "\r\n",
    "\tfor fonteDados in range(0, 2):\r\n",
    "\t\t# fonteDados = 0 --> dados com as palavras separadas manualmente\r\n",
    "\t\t# fonteDados = 1 --> dados sem as palavras separadas manualmente\r\n",
    "\r\n",
    "\t\tlinha  = 0\r\n",
    "\t\tcoluna = 0\r\n",
    "\t\t\r\n",
    "\t\t# Cria um Pipeline - Classificador Composto\r\n",
    "\t\t# vectorizer => transformer => classifier \r\n",
    "\t\ttext_clf = Pipeline([('counts' , CountVectorizer() ),\r\n",
    "\t\t\t\t\t\t#  ('tfidf', TfidfTransformer()),\r\n",
    "\t\t\t\t\t\t\t('classifier'  , MultinomialNB()   ),\r\n",
    "\t\t\t\t\t\t\t])\r\n",
    "\r\n",
    "\t\t# registra resultados\r\n",
    "\t\tdf_resultado[linha][          0] = 'Todos'\r\n",
    "\t\tdf_resultado[linha][ coluna + 1] = dfNFiscais.shape[0]\r\n",
    "\t\tdf_resultado[linha][ coluna + 2] = avalia_modelo(text_clf, dfNFiscais['NovaDescricao'], dfNFiscais['Categoria'])\r\n",
    "\r\n",
    "\t\tprint(linha,' : ',coluna+1)\r\n",
    "\t\tprint( df_resultado[linha][          0] )\r\n",
    "\t\tprint( df_resultado[linha][ coluna + 1] )\r\n",
    "\t\tprint( df_resultado[linha][ coluna + 2] )\r\n",
    "\t\tprint()\r\n",
    "\r\n",
    "\t\t# Cria um Pipeline - Classificador Composto\r\n",
    "\t\t# vectorizer => transformer => classifier \r\n",
    "\t\ttext_clf = Pipeline([('counts' , CountVectorizer() ),\r\n",
    "\t\t\t\t\t\t\t('tfidf', TfidfTransformer()),\r\n",
    "\t\t\t\t\t\t\t('classifier'  , MultinomialNB()   ),\r\n",
    "\t\t\t\t\t\t\t])\r\n",
    "\r\n",
    "\t\t# registra resultados\r\n",
    "\t\tdf_resultado[linha][ coluna + 3] = dfNFiscais.shape[0]\r\n",
    "\t\tdf_resultado[linha][ coluna + 4] = avalia_modelo(text_clf, dfNFiscais['NovaDescricao'], dfNFiscais['Categoria'])    \r\n",
    "\r\n",
    "\t\tprint(linha,' : ',coluna+3)\r\n",
    "\t\tprint( df_resultado[linha][          0] )\r\n",
    "\t\tprint( df_resultado[linha][ coluna + 3] )\r\n",
    "\t\tprint( df_resultado[linha][ coluna + 4] )\r\n",
    "\t\tprint()\r\n",
    "\r\n",
    "\t\t# calcula precisão para fornecedores\r\n",
    "\t\tfor fornecedor in fornecedores:\r\n",
    "\t\t\t\r\n",
    "\t\t\tlinha += 1\r\n",
    "\t\t\t\r\n",
    "\t\t\t# obtem dados do fornecedor\r\n",
    "\t\t\tmask = dfNFiscais[\"Remetente\"] == fornecedor\r\n",
    "\t\t\tdados_fornecedor = dfNFiscais[ mask ]\r\n",
    "\r\n",
    "\r\n",
    "\t\t\t# Cria um Pipeline - Classificador Composto\r\n",
    "\t\t\t# vectorizer => transformer => classifier \r\n",
    "\t\t\ttext_clf = Pipeline([('counts' , CountVectorizer() ),\r\n",
    "\t\t\t\t\t\t\t#  ('tfidf', TfidfTransformer()),\r\n",
    "\t\t\t\t\t\t\t\t('classifier'  , MultinomialNB()   ),\r\n",
    "\t\t\t\t\t\t\t\t])\r\n",
    "\r\n",
    "\t\t\t# registra resultados\r\n",
    "\t\t\tdf_resultado[linha][          0] = fornecedor\r\n",
    "\t\t\tdf_resultado[linha][ coluna + 1] = dados_fornecedor.shape[0]\r\n",
    "\t\t\tdf_resultado[linha][ coluna + 2] = avalia_modelo(text_clf, dados_fornecedor['NovaDescricao'], \r\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdados_fornecedor['Categoria'])\r\n",
    "\t\t\tprint(linha,' : ',coluna+1)\r\n",
    "\t\t\tprint( df_resultado[linha][          0] )\r\n",
    "\t\t\tprint( df_resultado[linha][ coluna + 1] )\r\n",
    "\t\t\tprint( df_resultado[linha][ coluna + 2] )\r\n",
    "\t\t\tprint()\r\n",
    "\r\n",
    "\t\t\t# Cria um Pipeline - Classificador Composto\r\n",
    "\t\t\t# vectorizer => transformer => classifier \r\n",
    "\t\t\ttext_clf = Pipeline([('counts' , CountVectorizer() ),\r\n",
    "\t\t\t\t\t\t\t\t('tfidf', TfidfTransformer()),\r\n",
    "\t\t\t\t\t\t\t\t('classifier'  , MultinomialNB()   ),\r\n",
    "\t\t\t\t\t\t\t\t])\r\n",
    "\r\n",
    "\t\t\t# registra resultados\r\n",
    "\t\t\tdf_resultado[linha][ coluna + 3] = dados_fornecedor.shape[0]\r\n",
    "\t\t\tdf_resultado[linha][ coluna + 4] = avalia_modelo(text_clf, dados_fornecedor['NovaDescricao'], \r\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdados_fornecedor['Categoria'])         \r\n",
    "\t\t\tprint(linha,' : ',coluna+3)\r\n",
    "\t\t\tprint( df_resultado[linha][          0] )\r\n",
    "\t\t\tprint( df_resultado[linha][ coluna + 3] )\r\n",
    "\t\t\tprint( df_resultado[linha][ coluna + 4] )\r\n",
    "\t\t\tprint()\r\n",
    "\r\n",
    "\treturn df_resultado\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# create the transform\r\n",
    "vectorizer = CountVectorizer()\r\n",
    "\r\n",
    "text = df['NovaDescricao']\r\n",
    "# tokenize and build vocab\r\n",
    "vectorizer.fit(text)\r\n",
    "\r\n",
    "# summarize\r\n",
    "print(vectorizer.vocabulary_)\r\n",
    "# encode document\r\n",
    "vector = vectorizer.transform(text)\r\n",
    "# summarize encoded vector\r\n",
    "print(vector.shape)\r\n",
    "print(type(vector))\r\n",
    "print(vector.toarray())\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7dd1d228260d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NovaDescricao'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# tokenize and build vocab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(vectorizer.vocabulary_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(vectorizer.vocabulary_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "palavras = list(vectorizer.vocabulary_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "palavras.sort()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(palavras)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_palavras = pd.DataFrame(data = palavras)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_palavras.to_csv('palavras.cvs', sep=\";\", index=False )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vocabulário = list( vectorizer.vocabulary_ )\r\n",
    "vocabulário"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vocabulário.sort()\r\n",
    "vocabulário"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def doNaiveBayers(dfNFiscais):    \r\n",
    "    fornecedores = doFornecedorCut(dfNFiscais, 1000)\r\n",
    "    resultado = doProcNaives(dfNFiscais, fornecedores)\r\n",
    "    \r\n",
    "    return resultado\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}