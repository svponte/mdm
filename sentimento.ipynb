{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import nltk\r\n",
    "from nltk.corpus import stopwords\r\n",
    "nltk.download('stopwords')\r\n",
    "%matplotlib inline"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\svpon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import import_ipynb\r\n",
    "from carga import doCarga\r\n",
    "diretorio = '..\\\\dados\\\\'\r\n",
    "dfNotas = doCarga(diretorio, opcao=3)\r\n",
    "dfNotas = dfNotas.drop(columns=['Remetente'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Separa os contadores\r\n",
    "count_class_0, count_class_1, count_class_2, count_class_3, count_class_4 = dfNotas['Categoria'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "dfNotas"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>NovaDescricao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0simsim</td>\n",
       "      <td>CACHACA SAO FRANCISCO 12X970M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0simsim</td>\n",
       "      <td>CACHACA YPIOCA EMP.OURO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0simsim</td>\n",
       "      <td>CACHACA YPIOCA OURO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0simsim</td>\n",
       "      <td>CACHACA YPIOCA PRATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0simsim</td>\n",
       "      <td>BB CACHACA SAGATIBA PURA  (12) GF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>38.0simnão</td>\n",
       "      <td>SHAMP.INF.BEBE NATUREZA SUAVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>38.0simnão</td>\n",
       "      <td>SHAMP.INF.BEBE NATUREZA SUAVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>38.0simnão</td>\n",
       "      <td>SHAMP.INF.CARROS II MCQUEEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>38.0simnão</td>\n",
       "      <td>SHAMP.INF.CARROS II MCQUEENNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>38.0simnão</td>\n",
       "      <td>SHAMP.INF.CARROS II MCQUEENNC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Categoria                      NovaDescricao\n",
       "0      30.0simsim      CACHACA SAO FRANCISCO 12X970M\n",
       "1      30.0simsim            CACHACA YPIOCA EMP.OURO\n",
       "2      30.0simsim                CACHACA YPIOCA OURO\n",
       "3      30.0simsim               CACHACA YPIOCA PRATA\n",
       "4      30.0simsim  BB CACHACA SAGATIBA PURA  (12) GF\n",
       "...           ...                                ...\n",
       "99995  38.0simnão      SHAMP.INF.BEBE NATUREZA SUAVE\n",
       "99996  38.0simnão      SHAMP.INF.BEBE NATUREZA SUAVE\n",
       "99997  38.0simnão        SHAMP.INF.CARROS II MCQUEEN\n",
       "99998  38.0simnão      SHAMP.INF.CARROS II MCQUEENNC\n",
       "99999  38.0simnão      SHAMP.INF.CARROS II MCQUEENNC\n",
       "\n",
       "[99146 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Divide datasets por classes\r\n",
    "\r\n",
    "df_class_0 = dfNotas[dfNotas['Categoria'] == \"31.0simsim\"]\r\n",
    "df_class_1 = dfNotas[dfNotas['Categoria'] == \"38.0simsim\"]\r\n",
    "df_class_2 = dfNotas[dfNotas['Categoria'] == \"38.0simnão\"] \r\n",
    "df_class_3 = dfNotas[dfNotas['Categoria'] == \"30.0simsim\"]         # Tamanho escolhido\r\n",
    "df_class_4 = dfNotas[dfNotas['Categoria'] == \"31.0nãonão\"]         # Classse MUITO pequena - UNDERSAMPLING\r\n",
    "\r\n",
    "# Equipara os tamanhos 30.0simsim que tem 3090 ocorrências\r\n",
    "# Foram equiparados ao tamanho da classe 3\r\n",
    "MaxSize = 3090 # df_class_3.size \r\n",
    "df_class_0 = df_class_0.sample(MaxSize)\r\n",
    "df_class_1 = df_class_1.sample(MaxSize)\r\n",
    "df_class_2 = df_class_2.sample(MaxSize)\r\n",
    "\r\n",
    "# Random Oversampling\r\n",
    "df_class_4 = df_class_4.sample(MaxSize, replace=True)\r\n",
    "\r\n",
    "# Agrupa novamente\r\n",
    "dfAjustado = pd.concat([df_class_0, df_class_1, df_class_2, df_class_3, df_class_4], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "dfAjustado = dfAjustado.sample(frac=1).reset_index(drop=True)\r\n",
    "base_treino = dfAjustado.iloc[:10300,:]\r\n",
    "base_teste = dfAjustado.iloc[10301:,:]\r\n",
    "\r\n",
    "#exemplo_base_treino.Categoria.value_counts()\r\n",
    "base_teste.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5149, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stop Words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "lista_Stop = nltk.corpus.stopwords.words('portuguese')\r\n",
    "#np.transpose(lista_Stop)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def removeStopWords(texto):\r\n",
    "    frases = []\r\n",
    "    for (palavras, sentimento) in texto:\r\n",
    "        # List Comprehension para pegar palavras fora do lista_Stop\r\n",
    "        semStop = [ p for p in palavras.split() if p not in lista_Stop]\r\n",
    "        frases.append((semStop, sentimento))\r\n",
    "    return frases"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stemming"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "def aplica_Stemmer(texto):\r\n",
    "    nltk.download('rslp')\r\n",
    "    stemmer = nltk.stem.RSLPStemmer()\r\n",
    "    frases_sem_Stemming = []\r\n",
    "    for ( Categoria, NovaDescricao) in texto:\r\n",
    "        com_Stemming = [str(stemmer.stem(p)) for p in NovaDescricao.split() if p not in lista_Stop]\r\n",
    "        frases_sem_Stemming.append((com_Stemming, Categoria))\r\n",
    "    return frases_sem_Stemming"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "frases_com_Stem_treinamento = aplica_Stemmer(base_treino.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\svpon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "pd.DataFrame(frases_com_Stem_treinamento, columns=['Categoria', 'Sentimento']).sample(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>[cred, icm, propri, conf., art.330,, 1., ref.a...</td>\n",
       "      <td>31.0nãonão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>[kit, sort, acessori, c/4, kit, 3un]</td>\n",
       "      <td>31.0nãonão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>[vin.port.tom, duorum]</td>\n",
       "      <td>31.0simsim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>[ag, ox, yam, 40v]</td>\n",
       "      <td>38.0simnão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8462</th>\n",
       "      <td>[sh, capicilin, ojon, mono, s/]</td>\n",
       "      <td>38.0simnão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>[cervej, skol, beat, sens, long]</td>\n",
       "      <td>31.0nãonão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5620</th>\n",
       "      <td>[oe, manjerica, terr, fl]</td>\n",
       "      <td>38.0simnão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8859</th>\n",
       "      <td>[esm, the, fusion, ros, ros]</td>\n",
       "      <td>38.0simsim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>[v., port., paul, laure, class, tint, 1,5, lt.]</td>\n",
       "      <td>31.0simsim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9279</th>\n",
       "      <td>[vin.fr.l, jamell, viogni]</td>\n",
       "      <td>31.0simsim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Categoria  Sentimento\n",
       "879   [cred, icm, propri, conf., art.330,, 1., ref.a...  31.0nãonão\n",
       "8514               [kit, sort, acessori, c/4, kit, 3un]  31.0nãonão\n",
       "5146                             [vin.port.tom, duorum]  31.0simsim\n",
       "6010                                 [ag, ox, yam, 40v]  38.0simnão\n",
       "8462                    [sh, capicilin, ojon, mono, s/]  38.0simnão\n",
       "3273                   [cervej, skol, beat, sens, long]  31.0nãonão\n",
       "5620                          [oe, manjerica, terr, fl]  38.0simnão\n",
       "8859                       [esm, the, fusion, ros, ros]  38.0simsim\n",
       "7622    [v., port., paul, laure, class, tint, 1,5, lt.]  31.0simsim\n",
       "9279                         [vin.fr.l, jamell, viogni]  31.0simsim"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "frases_com_Stem_teste = aplica_Stemmer(base_teste.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\svpon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "def busca_Palavras(frases):\r\n",
    "    todas_Palavras = []\r\n",
    "    for (palavras, Categoria) in frases:\r\n",
    "        todas_Palavras.extend(palavras)\r\n",
    "    return todas_Palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "palavras_treinamento = busca_Palavras(frases_com_Stem_treinamento)\r\n",
    "palavras_teste = busca_Palavras(frases_com_Stem_teste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "print ('Quantidade de palavras no treinamento {}'.format(pd.DataFrame(palavras_treinamento).count()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quantidade de palavras no treinamento 0    47981\n",
      "dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "def busca_frequencia(palavras):\r\n",
    "    palavras = nltk.FreqDist(palavras)\r\n",
    "    return palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "frequencia_treinamento = busca_frequencia(palavras_treinamento)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "frequencia_treinamento.most_common(20)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('sh', 1007),\n",
       " ('cachac', 996),\n",
       " ('esm', 743),\n",
       " ('beb', 469),\n",
       " ('kit', 442),\n",
       " ('conf', 435),\n",
       " ('aguard', 367),\n",
       " ('gf', 367),\n",
       " ('cervej', 340),\n",
       " ('6x1', 323),\n",
       " ('1.', 310),\n",
       " ('tto', 309),\n",
       " ('nf', 307),\n",
       " ('dec', 300),\n",
       " ('ressarc', 298),\n",
       " ('icm', 298),\n",
       " ('skol', 279),\n",
       " ('beat', 269),\n",
       " ('vinh', 263),\n",
       " ('lt', 249)]"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "frequencia_teste = busca_frequencia(palavras_teste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "def busca_palavras_unicas(frequencia):\r\n",
    "    freq = frequencia.keys()\r\n",
    "    return freq\r\n",
    "\r\n",
    "palavras_unicas_treinamento = busca_palavras_unicas(frequencia_treinamento)\r\n",
    "palavras_unicas_teste = busca_palavras_unicas(frequencia_teste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "def extrator_palavras(documento):\r\n",
    "    doc = set(documento)\r\n",
    "    caracteristicas = {}\r\n",
    "    for palavras in palavras_unicas_treinamento:\r\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\r\n",
    "    return caracteristicas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "def extrator_palavras_teste(documento):\r\n",
    "    doc = set(documento)\r\n",
    "    caracteristicas = {}\r\n",
    "    for palavras in palavras_unicas_teste:\r\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\r\n",
    "    return caracteristicas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "base_completa_treinamento = nltk.classify.apply_features(extrator_palavras, frases_com_Stem_treinamento)\r\n",
    "base_completa_teste = nltk.classify.apply_features(extrator_palavras_teste, frases_com_Stem_teste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naives"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "classificador = nltk.NaiveBayesClassifier.train(base_completa_treinamento)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "print(classificador.labels())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['30.0simsim', '31.0simsim', '31.0nãonão', '38.0simsim', '38.0simnão']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "print(classificador.show_most_informative_features(10))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n",
      "                      sh = True           38.0si : 38.0si =    403.6 : 1.0\n",
      "                  aguard = True           30.0si : 31.0si =    239.7 : 1.0\n",
      "                    sens = True           31.0nã : 38.0si =    127.4 : 1.0\n",
      "                      lt = True           31.0nã : 38.0si =    125.4 : 1.0\n",
      "                     art = True           31.0nã : 30.0si =    118.7 : 1.0\n",
      "                      v. = True           31.0si : 38.0si =    110.8 : 1.0\n",
      "                     cop = True           31.0nã : 38.0si =    105.2 : 1.0\n",
      "                     bco = True           31.0si : 38.0si =     91.5 : 1.0\n",
      "                      bl = True           38.0si : 31.0si =     88.8 : 1.0\n",
      "                      ag = True           30.0si : 38.0si =     78.6 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "print (nltk.classify.accuracy(classificador, base_completa_teste))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9728102544183337\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "erros = []\r\n",
    "for (frase, Categoria) in base_completa_teste:\r\n",
    "    resultado = classificador.classify(frase)\r\n",
    "    if resultado != Categoria:\r\n",
    "        erros.append((Categoria, resultado, frase))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "from nltk.metrics import ConfusionMatrix\r\n",
    "esperado = []\r\n",
    "previsto = []\r\n",
    "for (frase, Categoria) in base_completa_teste:\r\n",
    "    resultado = classificador.classify(frase)\r\n",
    "    previsto.append(resultado)\r\n",
    "    esperado.append(Categoria)\r\n",
    "\r\n",
    "matriz = ConfusionMatrix(esperado, previsto)\r\n",
    "print (matriz)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           |    3    3    3    3    3 |\n",
      "           |    0    1    1    8    8 |\n",
      "           |    .    .    .    .    . |\n",
      "           |    0    0    0    0    0 |\n",
      "           |    s    n    s    s    s |\n",
      "           |    i    ã    i    i    i |\n",
      "           |    m    o    m    m    m |\n",
      "           |    s    n    s    n    s |\n",
      "           |    i    ã    i    ã    i |\n",
      "           |    m    o    m    o    m |\n",
      "-----------+--------------------------+\n",
      "30.0simsim | <995>   .    3    1    . |\n",
      "31.0nãonão |   13<1003>   .    .    . |\n",
      "31.0simsim |   39    4 <990>   2    4 |\n",
      "38.0simnão |    8    .    5<1034>   5 |\n",
      "38.0simsim |   13    1    8   34 <987>|\n",
      "-----------+--------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}