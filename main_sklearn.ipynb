{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mineração de Dados Massivos\r\n",
    "## Analise de descrição de mercadorias de Notas Fiscais Eletrônicas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bibliotecas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Iniciando Ambiente\r\n",
    "import numpy as np, pandas as pd, time, random\r\n",
    "import datetime as dt\r\n",
    "\r\n",
    "import nltk\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import unicodedata\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import warnings\r\n",
    "from pylab import rcParams\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import precision_score, recall_score\r\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\r\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\r\n",
    "\r\n",
    "# Se necessário, descomente as linhas a seguir para ler as stopwords\r\n",
    "nltk.download('stopwords')\r\n",
    "nltk.download('rslp')\r\n",
    "stemmer = nltk.stem.RSLPStemmer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Módulos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Módulos de código de programação\r\n",
    "#!pip install import-ipynb\r\n",
    "import import_ipynb\r\n",
    "\r\n",
    "# Carga de Arquivos\r\n",
    "from carga import doCarga\r\n",
    "\r\n",
    "# Tratamento de Dados         \r\n",
    "from tratamento import doTratamento\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variáveis de Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Pasta aonde estão os dados\r\n",
    "diretorio = '..\\\\dados\\\\'\r\n",
    "#diretorio = \"F:\\\\Weisner\\\\Documentos\\\\MEGA Estudos\\\\UNB - MDM - Mineração de Dados Massivos\\\\Artigo\\\\\" \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Contador de tempo\r\n",
    "def tic():\r\n",
    "    global _start_time \r\n",
    "    _start_time = time.time()\r\n",
    "\r\n",
    "def tac():\r\n",
    "    t_sec = round(time.time() - _start_time)\r\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\r\n",
    "    (t_hour,t_min) = divmod(t_min,60) \r\n",
    "    print('Duração: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Carga dos dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Abrir arquivo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Carrega os dados\r\n",
    "dfNotas = doCarga(diretorio, opcao=3)\r\n",
    "print (\"{} registros carregados\".format(dfNotas.size))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processa se necessário"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# doTratamento(dfNotas, diretorio)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Amostra dos dados\r\n",
    "dfNotas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove a coluna de Remetente\r\n",
    "dfNotas = dfNotas.drop(columns=['Remetente'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Balanceamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Situação - AS-IS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.set(font_scale=1.4)\r\n",
    "dfNotas['Categoria'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\r\n",
    "plt.xlabel(\"Categorias\", labelpad=14)\r\n",
    "plt.ylabel(\"Registros\", labelpad=14)\r\n",
    "plt.title(\"Quantidade de categorias por registro\", y=1.02);\r\n",
    "\r\n",
    "plt.savefig('imagens/DisDesbalanceada.png', bbox_inches='tight');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfNotas['Categoria'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Separa os contadores\r\n",
    "count_class_0, count_class_1, count_class_2, count_class_3, count_class_4, count_class_5, count_class_6, count_class_7, count_class_8, count_class_9, count_class_10, count_class_11, count_class_12, count_class_13, count_class_14 = dfNotas['Categoria'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Divide datasets por classes\r\n",
    "df_class_0 = dfNotas[dfNotas['Categoria'] == \"41.0simnão\"]\r\n",
    "df_class_1 = dfNotas[dfNotas['Categoria'] == \"40.0simnão\"]\r\n",
    "df_class_2 = dfNotas[dfNotas['Categoria'] == \"38.0simnão\"]\r\n",
    "df_class_3 = dfNotas[dfNotas['Categoria'] == \"42.0simnão\"]\r\n",
    "df_class_4 = dfNotas[dfNotas['Categoria'] == \"31.0simsim\"]\r\n",
    "df_class_5 = dfNotas[dfNotas['Categoria'] == \"38.0simsim\"]\r\n",
    "df_class_6 = dfNotas[dfNotas['Categoria'] == \"40.0nãonão\"]\r\n",
    "df_class_7 = dfNotas[dfNotas['Categoria'] == \"38.0nãonão\"]\r\n",
    "df_class_8 = dfNotas[dfNotas['Categoria'] == \"39.0simnão\"]\r\n",
    "df_class_9 = dfNotas[dfNotas['Categoria'] == \"41.0nãonão\"]\r\n",
    "df_class_10 = dfNotas[dfNotas['Categoria'] == \"39.0nãonão\"]\r\n",
    "df_class_11 = dfNotas[dfNotas['Categoria'] == \"42.0nãonão\"]\r\n",
    "df_class_12 = dfNotas[dfNotas['Categoria'] == \"30.0simsim\"] # Tamanho escolhido\r\n",
    "df_class_13 = dfNotas[dfNotas['Categoria'] == \"31.0nãonão\"] # 182 - poucos registros\r\n",
    "df_class_14 = dfNotas[dfNotas['Categoria'] == \"30.0nãonão\"] # 9 - insignificante\r\n",
    "\r\n",
    "# Equipara os tamanhos 30.0simsim\r\n",
    "# Foram equiparados ao tamanho da classe 3\r\n",
    "#MaxSize = df_class_3.size \r\n",
    "#MaxSize = 3000 # df_class_3.size \r\n",
    "MaxSize = 2500 # df_class_3.size "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Undersampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Faz o undersampling a partir de amostras aleatórias\r\n",
    "df_class_0 = df_class_0.sample(MaxSize)\r\n",
    "df_class_1 = df_class_1.sample(MaxSize)\r\n",
    "df_class_2 = df_class_2.sample(MaxSize)\r\n",
    "df_class_3 = df_class_3.sample(MaxSize)\r\n",
    "df_class_4 = df_class_4.sample(MaxSize)\r\n",
    "df_class_5 = df_class_5.sample(MaxSize)\r\n",
    "df_class_6 = df_class_6.sample(MaxSize)\r\n",
    "df_class_7 = df_class_7.sample(MaxSize)\r\n",
    "df_class_8 = df_class_8.sample(MaxSize)\r\n",
    "df_class_9 = df_class_9.sample(MaxSize)\r\n",
    "df_class_10 = df_class_10.sample(MaxSize)\r\n",
    "df_class_11 = df_class_11.sample(MaxSize)\r\n",
    "df_class_12 = df_class_12.sample(MaxSize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Oversampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Oversampling\r\n",
    "df_class_13 = df_class_13.sample(MaxSize, replace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reagrupa"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Agrupa novamente\r\n",
    "dfAjustado = pd.concat([df_class_0, df_class_1, df_class_2, df_class_3, df_class_4, df_class_5, df_class_6, df_class_7, df_class_8, df_class_9, df_class_10, df_class_11, df_class_12, df_class_13], axis=0)\r\n",
    "dfAjustado = dfAjustado.sample(frac = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resultado - Dataset Balanceado"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Gera imagem do balanceamento ajustado\r\n",
    "sns.set(font_scale=1.4)\r\n",
    "dfAjustado['Categoria'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\r\n",
    "plt.xlabel(\"Categorias\", labelpad=14)\r\n",
    "plt.ylabel(\"Registros\", labelpad=14)\r\n",
    "plt.title(\"Quantidade de categorias por registro\", y=1.02);\r\n",
    "plt.savefig('imagens/DisBalanceada.png', bbox_inches='tight');  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfAjustado.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfAjustado = dfAjustado.sample(frac=1).reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scikit-learn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz, DecisionTreeRegressor\r\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "from sklearn.linear_model import Perceptron\r\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trata Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# X e y"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# CARGA - X e y\r\n",
    "X = dfAjustado['NovaDescricao']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = dfAjustado['Categoria'] \r\n",
    "le = preprocessing.LabelEncoder()\r\n",
    "le.fit(y)\r\n",
    "y = pd.DataFrame(le.transform(y))\r\n",
    "y_nomes = le.classes_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Divide Teste e Treino"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train.count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classificadores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Naive Bayes\r\n",
    "NB_clf = Pipeline([\r\n",
    "    ('vect', CountVectorizer()),\r\n",
    "    ('tfidf', TfidfTransformer()),\r\n",
    "    ('clf', MultinomialNB()),\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Treina\r\n",
    "NB_clf.fit(X_train, y_train.values.ravel())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Score\r\n",
    "NB_clf.score(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediz\r\n",
    "NB_predicted = NB_clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Metricas\r\n",
    "print(metrics.classification_report(y_test, NB_predicted, target_names=y_nomes)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM\r\n",
    "SVM_clf = Pipeline([\r\n",
    "    ('vect', CountVectorizer()),\r\n",
    "    ('tfidf', TfidfTransformer()),\r\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\r\n",
    "                           alpha=1e-3, random_state=42,\r\n",
    "                           max_iter=5, tol=None)),\r\n",
    "    ])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Treina\r\n",
    "SVM_clf.fit(X_train, y_train.values.ravel())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Score\r\n",
    "SVM_clf.score(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediz\r\n",
    "SGD_predicted = SVM_clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Metricas\r\n",
    "print(metrics.classification_report(y_test, SGD_predicted, target_names=y_nomes)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grid Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# Grid Search\r\n",
    "\r\n",
    "parameters = {\r\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\r\n",
    "    'tfidf__use_idf': (True, False),\r\n",
    "    'clf__alpha': (1e-2, 1e-3),\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "gs_clf.fit(X_train, y_train.values.ravel())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        SGDClassifier(alpha=0.001, max_iter=5,\n",
       "                                                      random_state=42,\n",
       "                                                      tol=None))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__alpha': (0.01, 0.001),\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# Melhor Resultado\r\n",
    "gs_clf.best_score_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8708315565031984"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# Melhores Parametros\r\n",
    "for param_name in sorted(parameters.keys()):\r\n",
    "     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "predicted = gs_clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "print(metrics.classification_report(y_test, predicted, target_names=y_nomes)) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  30.0simsim       0.94      0.99      0.96       820\n",
      "  31.0nãonão       0.90      0.98      0.94       843\n",
      "  31.0simsim       0.92      0.96      0.94       854\n",
      "  38.0nãonão       0.82      0.83      0.82       808\n",
      "  38.0simnão       0.84      0.88      0.86       834\n",
      "  38.0simsim       0.89      0.89      0.89       844\n",
      "  39.0nãonão       0.83      0.87      0.85       818\n",
      "  39.0simnão       0.89      0.84      0.86       845\n",
      "  40.0nãonão       0.89      0.80      0.84       820\n",
      "  40.0simnão       0.84      0.83      0.83       808\n",
      "  41.0nãonão       0.88      0.74      0.80       796\n",
      "  41.0simnão       0.90      0.80      0.84       806\n",
      "  42.0nãonão       0.92      0.96      0.94       847\n",
      "  42.0simnão       0.84      0.91      0.87       807\n",
      "\n",
      "    accuracy                           0.88     11550\n",
      "   macro avg       0.88      0.88      0.88     11550\n",
      "weighted avg       0.88      0.88      0.88     11550\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classificadores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# um classificador linear que utiliza o Gradiente Descendente Estocástico como método de treino. \r\n",
    "# Por padrão, utiliza o estimador SVM.\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "# Uma rede neural Perceptron Multicamadas\r\n",
    "from sklearn.neural_network import MLPClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classificadores = {\r\n",
    "    'SVM': SGDClassifier(loss='hinge', penalty='l2',\r\n",
    "                           alpha=1e-3, random_state=42,\r\n",
    "                           max_iter=5, tol=None),\r\n",
    "    'SGD': SGDClassifier(max_iter=5),\r\n",
    "    'Perceptron': Perceptron(),\r\n",
    "    'NB Multinomial': MultinomialNB(alpha=0.01),\r\n",
    "    'Passive-Aggressive': PassiveAggressiveClassifier()\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cls_stats = {}\r\n",
    "for cls_name in classificadores:\r\n",
    "    stats = {'n_train': 0, 'n_train_pos': 0,\r\n",
    "             'accuracy': 0.0, 'accuracy_history': [(0, 0)], 't0': time.time(),\r\n",
    "             'runtime_history': [(0, 0)], 'total_fit_time': 0.0}\r\n",
    "    cls_stats[cls_name] = stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "total_vect_time = 0\r\n",
    "for cls_name, cls in classificadores.items():\r\n",
    "\ttick = time.time()\r\n",
    "\r\n",
    "\tppl = Pipeline([\r\n",
    "     ('vect', CountVectorizer()),\r\n",
    "     ('tfidf', TfidfTransformer()),\r\n",
    "     ('clf', cls),\r\n",
    "\t ])\r\n",
    "\t\r\n",
    "\tprint (cls_name)\r\n",
    "\tppl.fit(X_train, y_train.values.ravel())\r\n",
    "\r\n",
    "\t# accumulate test accuracy stats\r\n",
    "\tcls_stats[cls_name]['total_fit_time'] = time.time() - tick\r\n",
    "\tcls_stats[cls_name]['n_train'] = X_train.shape[0]\r\n",
    "\t#cls_stats[cls_name]['n_train_pos'] += sum(y_train)\r\n",
    "\ttick = time.time()\r\n",
    "\tcls_stats[cls_name]['accuracy'] = cls.score(X_test, y_test) \r\n",
    "\tcls_stats[cls_name]['prediction_time'] = time.time() - tick\r\n",
    "\tacc_history = (cls_stats[cls_name]['accuracy'], cls_stats[cls_name]['n_train'])\r\n",
    "\tcls_stats[cls_name]['accuracy_history'].append(acc_history)\r\n",
    "\trun_history = (cls_stats[cls_name]['accuracy'], total_vect_time + cls_stats[cls_name]['total_fit_time'])\r\n",
    "\tcls_stats[cls_name]['runtime_history'].append(run_history)\r\n",
    "\r\n",
    "\tprint (cls_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Out of Core"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\r\n",
    "from sklearn.linear_model import Perceptron\r\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\r\n",
    "import itertools"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vectorizer = HashingVectorizer(decode_error='ignore', n_features=2 ** 18,\r\n",
    "                               alternate_sign=False)\r\n",
    "\r\n",
    "\r\n",
    "# We learn a binary classification between the \"acq\" class and all the others.\r\n",
    "# \"acq\" was chosen as it is more or less evenly distributed in the Reuters\r\n",
    "# files. For other datasets, one should take care of creating a test set with\r\n",
    "# a realistic portion of positive instances.\r\n",
    "#all_classes = np.array([0, 1])\r\n",
    "#positive_class = 'acq'\r\n",
    "all_classes = y_nomes\r\n",
    "\r\n",
    "# Here are some classifiers that support the `partial_fit` method\r\n",
    "partial_fit_classifiers = {\r\n",
    "    'SGD': SGDClassifier(max_iter=5),\r\n",
    "    'Perceptron': Perceptron(),\r\n",
    "    'NB Multinomial': MultinomialNB(alpha=0.01),\r\n",
    "    'Passive-Aggressive': PassiveAggressiveClassifier(),\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_minibatch(doc_iter, size): #, pos_class=positive_class):\r\n",
    "    \"\"\"Extract a minibatch of examples, return a tuple X_text, y.\r\n",
    "\r\n",
    "    Note: size is before excluding invalid docs with no topics assigned.\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    #data = [('{title}\\n\\n{body}'.format(**doc), pos_class in doc['topics'])\r\n",
    "    #        for doc in itertools.islice(doc_iter, size)\r\n",
    "    #        if doc['topics']]\r\n",
    "    # NovaDescricao Classificacao\r\n",
    "    \r\n",
    "    data = doc_iter.iloc[:size,:]\r\n",
    "\r\n",
    "    #if not len(data):\r\n",
    "    #    return np.asarray([], dtype=int), np.asarray([], dtype=int)\r\n",
    "    X_text = data['NovaDescricao'] \r\n",
    "    y = data['Categoria']\r\n",
    "    return X_text, np.asarray(y) #, dtype=int)\r\n",
    "\r\n",
    "def iter_minibatches(doc_iter, minibatch_size):\r\n",
    "    \"\"\"Generator of minibatches.\"\"\"\r\n",
    "    X_text, y = get_minibatch(doc_iter, minibatch_size)\r\n",
    "    while len(X_text):\r\n",
    "        yield X_text, y\r\n",
    "        X_text, y = get_minibatch(doc_iter, minibatch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test data statistics\r\n",
    "test_stats = {'n_test': 0, 'n_test_pos': 0}\r\n",
    "\r\n",
    "# First we hold out a number of examples to estimate accuracy\r\n",
    "n_test_documents = 1000\r\n",
    "tick = time.time()\r\n",
    "X_test_text, y_test = get_minibatch(dfAjustado, 1000)\r\n",
    "parsing_time = time.time() - tick\r\n",
    "tick = time.time()\r\n",
    "X_test = vectorizer.transform(X_test_text)\r\n",
    "vectorizing_time = time.time() - tick\r\n",
    "test_stats['n_test'] += len(y_test)\r\n",
    "#test_stats['n_test_pos'] += sum(y_test)\r\n",
    "#print(\"Test set is %d documents (%d positive)\" % (len(y_test), sum(y_test)))\r\n",
    "print(\"Test set is %d documents\" % (len(y_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def progress(cls_name, stats):\r\n",
    "    \"\"\"Report progress information, return a string.\"\"\"\r\n",
    "    duration = time.time() - stats['t0']\r\n",
    "    s = \"%20s classifier : \\t\" % cls_name\r\n",
    "    s += \"%(n_train)6d train docs (%(n_train_pos)6d positive) \" % stats\r\n",
    "    s += \"%(n_test)6d test docs (%(n_test_pos)6d positive) \" % test_stats\r\n",
    "    s += \"accuracy: %(accuracy).3f \" % stats\r\n",
    "    s += \"in %.2fs (%5d docs/s)\" % (duration, stats['n_train'] / duration)\r\n",
    "    return s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "cls_stats = {}\r\n",
    "\r\n",
    "for cls_name in partial_fit_classifiers:\r\n",
    "    stats = {'n_train': 0, 'n_train_pos': 0,\r\n",
    "             'accuracy': 0.0, 'accuracy_history': [(0, 0)], 't0': time.time(),\r\n",
    "             'runtime_history': [(0, 0)], 'total_fit_time': 0.0}\r\n",
    "    cls_stats[cls_name] = stats\r\n",
    "\r\n",
    "get_minibatch(dfAjustado, n_test_documents)\r\n",
    "# Discard test set\r\n",
    "\r\n",
    "# We will feed the classifier with mini-batches of 1000 documents; this means\r\n",
    "# we have at most 1000 docs in memory at any time.  The smaller the document\r\n",
    "# batch, the bigger the relative overhead of the partial fit methods.\r\n",
    "minibatch_size = 1000\r\n",
    "\r\n",
    "# Create the data_stream that parses Reuters SGML files and iterates on\r\n",
    "# documents as a stream.\r\n",
    "minibatch_iterators = iter_minibatches(dfAjustado, minibatch_size)\r\n",
    "total_vect_time = 0.0\r\n",
    "\r\n",
    "# Main loop : iterate on mini-batches of examples\r\n",
    "for i, (X_train_text, y_train) in enumerate(minibatch_iterators):\r\n",
    "\r\n",
    "    tick = time.time()\r\n",
    "    X_train = vectorizer.transform(X_train_text)\r\n",
    "    total_vect_time += time.time() - tick\r\n",
    "\r\n",
    "    for cls_name, cls in partial_fit_classifiers.items():\r\n",
    "        tick = time.time()\r\n",
    "        # update estimator with examples in the current mini-batch\r\n",
    "        cls.partial_fit(X_train, y_train, classes=all_classes)\r\n",
    "\r\n",
    "        # accumulate test accuracy stats\r\n",
    "        cls_stats[cls_name]['total_fit_time'] += time.time() - tick\r\n",
    "        cls_stats[cls_name]['n_train'] += X_train.shape[0]\r\n",
    "        #cls_stats[cls_name]['n_train_pos'] += sum(y_train)\r\n",
    "        tick = time.time()\r\n",
    "        cls_stats[cls_name]['accuracy'] = cls.score(X_test, y_test)\r\n",
    "        cls_stats[cls_name]['prediction_time'] = time.time() - tick\r\n",
    "        acc_history = (cls_stats[cls_name]['accuracy'],\r\n",
    "                       cls_stats[cls_name]['n_train'])\r\n",
    "        cls_stats[cls_name]['accuracy_history'].append(acc_history)\r\n",
    "        run_history = (cls_stats[cls_name]['accuracy'],\r\n",
    "                       total_vect_time + cls_stats[cls_name]['total_fit_time'])\r\n",
    "        cls_stats[cls_name]['runtime_history'].append(run_history)\r\n",
    "\r\n",
    "        if i % 3 == 0:\r\n",
    "            print(progress(cls_name, cls_stats[cls_name]))\r\n",
    "    if i % 3 == 0:\r\n",
    "        print('\\n')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}