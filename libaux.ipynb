{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Biblioteca de funções"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Funções Auxiliares"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Contador de tempo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Contador de tempo\r\n",
    "def tic():\r\n",
    "    global _start_time \r\n",
    "    _start_time = time.time()\r\n",
    "\r\n",
    "def tac():\r\n",
    "    t_sec = round(time.time() - _start_time)\r\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\r\n",
    "    (t_hour,t_min) = divmod(t_min,60) \r\n",
    "    print('Duração: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stopwords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Função para retirar as StopWords do Corpus\r\n",
    "def removeStopWords(texto, lista_Stop):\r\n",
    "    frases = []\r\n",
    "    for (palavras, sentimento) in texto:\r\n",
    "        # List Comprehension para pegar palavras fora do lista_Stop\r\n",
    "        semStop = [ p for p in palavras.split() if p not in lista_Stop]\r\n",
    "        frases.append((semStop, sentimento))\r\n",
    "    return frases"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stemming"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Remover sufixos e prefixos das palavras\r\n",
    "def aplica_Stemmer(texto):\r\n",
    "    global nltk\r\n",
    "    global lista_Stop\r\n",
    "    nltk.download('rslp')\r\n",
    "    stemmer = nltk.stem.RSLPStemmer()\r\n",
    "    frases_sem_Stemming = []\r\n",
    "    for ( Categoria, NovaDescricao) in texto:\r\n",
    "        com_Stemming = [str(stemmer.stem(p)) for p in NovaDescricao.split() if p not in lista_Stop]\r\n",
    "        frases_sem_Stemming.append((com_Stemming, Categoria))\r\n",
    "    return frases_sem_Stemming"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ajustes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Função para retornar apenas as palavras, sem a classificação (sentimento)\r\n",
    "def busca_Palavras(frases):\r\n",
    "    todas_Palavras = []\r\n",
    "    for (palavras, Categoria) in frases:\r\n",
    "        todas_Palavras.extend(palavras)\r\n",
    "    return todas_Palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Função para verificar a quantidade de vezes que a palavra é mencionada\r\n",
    "def busca_frequencia(palavras):\r\n",
    "    global nltk\r\n",
    "    palavras = nltk.FreqDist(palavras)\r\n",
    "    return palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Análise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Função para retornar somente as palavras únicas\r\n",
    "def busca_palavras_unicas(frequencia):\r\n",
    "    freq = frequencia.keys()\r\n",
    "    return freq\r\n",
    "\r\n",
    "#palavras_unicas_treinamento = busca_palavras_unicas(frequencia_treinamento)\r\n",
    "#palavras_unicas_teste = busca_palavras_unicas(frequencia_teste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Função para identificar quais palavras únicas estão no documento passo para função\r\n",
    "def extrator_palavras(documento):\r\n",
    "    global palavras_unicas_treinamento\r\n",
    "    doc = set(documento)\r\n",
    "    caracteristicas = {}\r\n",
    "    for palavras in palavras_unicas_treinamento:\r\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\r\n",
    "    return caracteristicas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Mesmo anterior, só que dedicada para teste\r\n",
    "def extrator_palavras_teste(documento):\r\n",
    "    global palavras_unicas_teste\r\n",
    "    doc = set(documento)\r\n",
    "    caracteristicas = {}\r\n",
    "    for palavras in palavras_unicas_teste:\r\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\r\n",
    "    return caracteristicas"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}