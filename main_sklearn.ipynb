{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mineração de Dados Massivos\r\n",
    "## Analise de descrição de mercadorias de Notas Fiscais Eletrônicas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bibliotecas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Iniciando Ambiente\r\n",
    "import numpy as np, pandas as pd, time, random\r\n",
    "import datetime as dt\r\n",
    "\r\n",
    "import nltk\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import unicodedata\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import warnings\r\n",
    "from pylab import rcParams\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import precision_score, recall_score\r\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\r\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\r\n",
    "\r\n",
    "# Se necessário, descomente as linhas a seguir para ler as stopwords\r\n",
    "nltk.download('stopwords')\r\n",
    "nltk.download('rslp')\r\n",
    "stemmer = nltk.stem.RSLPStemmer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Módulos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Módulos de código de programação\r\n",
    "#!pip install import-ipynb\r\n",
    "import import_ipynb\r\n",
    "\r\n",
    "# Carga de Arquivos\r\n",
    "from carga import doCarga\r\n",
    "\r\n",
    "# Tratamento de Dados         \r\n",
    "from tratamento import doTratamento\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variáveis de Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Pasta aonde estão os dados\r\n",
    "diretorio = '..\\\\dados\\\\'\r\n",
    "#diretorio = \"F:\\\\Weisner\\\\Documentos\\\\MEGA Estudos\\\\UNB - MDM - Mineração de Dados Massivos\\\\Artigo\\\\\" \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Contador de tempo\r\n",
    "def tic():\r\n",
    "    global _start_time \r\n",
    "    _start_time = time.time()\r\n",
    "\r\n",
    "def tac():\r\n",
    "    t_sec = round(time.time() - _start_time)\r\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\r\n",
    "    (t_hour,t_min) = divmod(t_min,60) \r\n",
    "    print('Duração: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Carga dos dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Abrir arquivo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Carrega os dados\r\n",
    "dfNotas = doCarga(diretorio, opcao=3)\r\n",
    "print (\"{} registros carregados\".format(dfNotas.size))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processa se necessário"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# doTratamento(dfNotas, diretorio)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Amostra dos dados\r\n",
    "dfNotas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove a coluna de Remetente\r\n",
    "dfNotas = dfNotas.drop(columns=['Remetente'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Balanceamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Situação - AS-IS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.set(font_scale=1.4)\r\n",
    "dfNotas['Categoria'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\r\n",
    "plt.xlabel(\"Categorias\", labelpad=14)\r\n",
    "plt.ylabel(\"Registros\", labelpad=14)\r\n",
    "plt.title(\"Quantidade de categorias por registro\", y=1.02);\r\n",
    "\r\n",
    "plt.savefig('imagens/DisDesbalanceada.png', bbox_inches='tight');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfNotas['Categoria'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Separa os contadores\r\n",
    "count_class_0, count_class_1, count_class_2, count_class_3, count_class_4, count_class_5, count_class_6, count_class_7, count_class_8, count_class_9, count_class_10, count_class_11, count_class_12, count_class_13, count_class_14 = dfNotas['Categoria'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Divide datasets por classes\r\n",
    "df_class_0 = dfNotas[dfNotas['Categoria'] == \"41.0simnão\"]\r\n",
    "df_class_1 = dfNotas[dfNotas['Categoria'] == \"40.0simnão\"]\r\n",
    "df_class_2 = dfNotas[dfNotas['Categoria'] == \"38.0simnão\"]\r\n",
    "df_class_3 = dfNotas[dfNotas['Categoria'] == \"42.0simnão\"]\r\n",
    "df_class_4 = dfNotas[dfNotas['Categoria'] == \"31.0simsim\"]\r\n",
    "df_class_5 = dfNotas[dfNotas['Categoria'] == \"38.0simsim\"]\r\n",
    "df_class_6 = dfNotas[dfNotas['Categoria'] == \"40.0nãonão\"]\r\n",
    "df_class_7 = dfNotas[dfNotas['Categoria'] == \"38.0nãonão\"]\r\n",
    "df_class_8 = dfNotas[dfNotas['Categoria'] == \"39.0simnão\"]\r\n",
    "df_class_9 = dfNotas[dfNotas['Categoria'] == \"41.0nãonão\"]\r\n",
    "df_class_10 = dfNotas[dfNotas['Categoria'] == \"39.0nãonão\"]\r\n",
    "df_class_11 = dfNotas[dfNotas['Categoria'] == \"42.0nãonão\"]\r\n",
    "df_class_12 = dfNotas[dfNotas['Categoria'] == \"30.0simsim\"] # Tamanho escolhido\r\n",
    "df_class_13 = dfNotas[dfNotas['Categoria'] == \"31.0nãonão\"] # 182 - poucos registros\r\n",
    "df_class_14 = dfNotas[dfNotas['Categoria'] == \"30.0nãonão\"] # 9 - insignificante\r\n",
    "\r\n",
    "# Equipara os tamanhos 30.0simsim\r\n",
    "# Foram equiparados ao tamanho da classe 3\r\n",
    "#MaxSize = df_class_3.size \r\n",
    "#MaxSize = 3000 # df_class_3.size \r\n",
    "MaxSize = 2500 # df_class_3.size "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Undersampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Faz o undersampling a partir de amostras aleatórias\r\n",
    "df_class_0 = df_class_0.sample(MaxSize)\r\n",
    "df_class_1 = df_class_1.sample(MaxSize)\r\n",
    "df_class_2 = df_class_2.sample(MaxSize)\r\n",
    "df_class_3 = df_class_3.sample(MaxSize)\r\n",
    "df_class_4 = df_class_4.sample(MaxSize)\r\n",
    "df_class_5 = df_class_5.sample(MaxSize)\r\n",
    "df_class_6 = df_class_6.sample(MaxSize)\r\n",
    "df_class_7 = df_class_7.sample(MaxSize)\r\n",
    "df_class_8 = df_class_8.sample(MaxSize)\r\n",
    "df_class_9 = df_class_9.sample(MaxSize)\r\n",
    "df_class_10 = df_class_10.sample(MaxSize)\r\n",
    "df_class_11 = df_class_11.sample(MaxSize)\r\n",
    "df_class_12 = df_class_12.sample(MaxSize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Oversampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Oversampling\r\n",
    "df_class_13 = df_class_13.sample(MaxSize, replace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reagrupa"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Agrupa novamente\r\n",
    "dfAjustado = pd.concat([df_class_0, df_class_1, df_class_2, df_class_3, df_class_4, df_class_5, df_class_6, df_class_7, df_class_8, df_class_9, df_class_10, df_class_11, df_class_12, df_class_13], axis=0)\r\n",
    "dfAjustado = dfAjustado.sample(frac = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resultado - Dataset Balanceado"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Gera imagem do balanceamento ajustado\r\n",
    "sns.set(font_scale=1.4)\r\n",
    "dfAjustado['Categoria'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\r\n",
    "plt.xlabel(\"Categorias\", labelpad=14)\r\n",
    "plt.ylabel(\"Registros\", labelpad=14)\r\n",
    "plt.title(\"Quantidade de categorias por registro\", y=1.02);\r\n",
    "plt.savefig('imagens/DisBalanceada.png', bbox_inches='tight');  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfAjustado.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfAjustado = dfAjustado.sample(frac=1).reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scikit-learn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz, DecisionTreeRegressor\r\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "from sklearn.linear_model import Perceptron\r\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trata Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# X e y"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# CARGA - X e y\r\n",
    "X = dfAjustado['NovaDescricao']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = dfAjustado['Categoria'] \r\n",
    "le = preprocessing.LabelEncoder()\r\n",
    "le.fit(y)\r\n",
    "y = pd.DataFrame(le.transform(y))\r\n",
    "y_nomes = le.classes_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Divide Teste e Treino"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train.count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classificadores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Naive Bayes\r\n",
    "NB_clf = Pipeline([\r\n",
    "    ('vect', CountVectorizer()),\r\n",
    "    ('tfidf', TfidfTransformer()),\r\n",
    "    ('clf', MultinomialNB()),\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Treina\r\n",
    "NB_clf.fit(X_train, y_train.values.ravel())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Score\r\n",
    "NB_clf.score(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediz\r\n",
    "NB_predicted = NB_clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Metricas\r\n",
    "print(metrics.classification_report(y_test, NB_predicted, target_names=y_nomes)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM\r\n",
    "SVM_clf = Pipeline([\r\n",
    "    ('vect', CountVectorizer()),\r\n",
    "    ('tfidf', TfidfTransformer()),\r\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\r\n",
    "                           alpha=1e-3, random_state=42,\r\n",
    "                           max_iter=5, tol=None)),\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Treina\r\n",
    "SVM_clf.fit(X_train, y_train.values.ravel())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Score\r\n",
    "SVM_clf.score(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediz\r\n",
    "SGD_predicted = SVM_clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Metricas\r\n",
    "print(metrics.classification_report(y_test, SGD_predicted, target_names=y_nomes)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Precepton"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Perceptron\r\n",
    "PRE_clf = Pipeline([\r\n",
    "    ('vect', CountVectorizer()),\r\n",
    "    ('tfidf', TfidfTransformer()),\r\n",
    "    ('clf', Perceptron()),\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Treina\r\n",
    "PRE_clf.fit(X_train, y_train.values.ravel())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Score\r\n",
    "PRE_clf.score(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediz\r\n",
    "PRE_predicted = PRE_clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Metricas\r\n",
    "print(metrics.classification_report(y_test, PRE_predicted, target_names=y_nomes)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Passive-Aggressive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Passive-Aggressive\r\n",
    "PAG_clf = Pipeline([\r\n",
    "    ('vect', CountVectorizer()),\r\n",
    "    ('tfidf', TfidfTransformer()),\r\n",
    "    ('clf',  PassiveAggressiveClassifier()),\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Treina\r\n",
    "PAG_clf.fit(X_train, y_train.values.ravel())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Score\r\n",
    "PAG_clf.score(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediz\r\n",
    "PRE_predicted = PAG_clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Metricas\r\n",
    "print(metrics.classification_report(y_test, PRE_predicted, target_names=y_nomes)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grid Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Grid Search\r\n",
    "\r\n",
    "parameters = {\r\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\r\n",
    "    'tfidf__use_idf': (True, False),\r\n",
    "    'clf__alpha': (1e-2, 1e-3),\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gs_clf.fit(X_train, y_train.values.ravel())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Melhor Resultado\r\n",
    "gs_clf.best_score_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Melhores Parametros\r\n",
    "for param_name in sorted(parameters.keys()):\r\n",
    "     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predicted = gs_clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(metrics.classification_report(y_test, predicted, target_names=y_nomes)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "from functools import reduce\r\n",
    "\r\n",
    "def _get_model_name(model):\r\n",
    "    \"\"\"\r\n",
    "            Returns a string with the name of a sklearn model\r\n",
    "                model: Sklearn stimator class\r\n",
    "    \"\"\"\r\n",
    "    if isinstance(model, Pipeline):\r\n",
    "        estimator = model.steps[-1][1]\r\n",
    "        name = \"Pipeline_\" + str(estimator)[:str(estimator).find(\"(\")]\r\n",
    "    else: \r\n",
    "        name = str(model)[:str(model).find(\"(\")]\r\n",
    "    return name\r\n",
    "    \r\n",
    "    \r\n",
    "def plot_cv_score(X, y, models_list, cv = 5, scoring_list = None, refit = True, return_scores = False):\r\n",
    "    \"\"\" \r\n",
    "            X: numpy_array/pandas dataframe n_rows, m_features\r\n",
    "            y: numpy_array/pandas dataframe n_rows\r\n",
    "            Plots min, max and avg kfold crosval_score for a list of models\r\n",
    "        \r\n",
    "    \"\"\"\r\n",
    "    names, mean_score = list(), list()\r\n",
    "    ldf = list()\r\n",
    "    mnames = list()\r\n",
    "    \r\n",
    "    for i, model in enumerate(models_list):\r\n",
    "        name = _get_model_name(model)\r\n",
    "        print (name)\r\n",
    "        clf = Pipeline([\r\n",
    "            ('vect', CountVectorizer()),\r\n",
    "            ('tfidf', TfidfTransformer()),\r\n",
    "            ('clf',  model),\r\n",
    "            ])\r\n",
    "\r\n",
    "        if refit:\r\n",
    "            clf.fit(X, y)\r\n",
    "        for metric in score_list:\r\n",
    "            score = cross_val_score(clf, X, y, cv = cv, scoring = metric, n_jobs= -1)\r\n",
    "            mean_score.append(np.mean(score))\r\n",
    "        tmp = pd.DataFrame({name: mean_score}, index = score_list)\r\n",
    "        ldf.append(tmp)\r\n",
    "        mean_score = list()\r\n",
    "        \r\n",
    "    frame_scores = reduce(lambda x,y: pd.merge(x,y, left_index = True, right_index = True), ldf).T\r\n",
    "    fig, ax  = plt.subplots(1,1, figsize = (10,5))\r\n",
    "\r\n",
    "    frame_scores.plot.bar(ax = ax, cmap = 'RdYlBu', edgecolor = \"black\")\r\n",
    "    ax.legend(loc = 'best')\r\n",
    "    ax.set_xlabel(\"Score\")\r\n",
    "    ax.set_title(\"Cross validation model benchmark\")\r\n",
    "\r\n",
    "    if return_scores:    \r\n",
    "        return frame_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\r\n",
    "from sklearn.datasets import load_breast_cancer\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "\r\n",
    "#X, y = load_breast_cancer(return_X_y= True)\r\n",
    "\r\n",
    "models_list =[LogisticRegression(random_state= 42),\r\n",
    "              SVC(probability= True),\r\n",
    "              RandomForestClassifier(random_state = 42),\r\n",
    "              GaussianNB()]\r\n",
    "\r\n",
    "score_list = [\"roc_auc\", \"accuracy\", \"f1\", \"precision\", \"recall\"]\r\n",
    "\r\n",
    "t = plot_cv_score(X = X_train, y = y_train.values.ravel(), models_list = models_list, cv = 5, scoring_list = score_list, refit = True)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-410e9830fc5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mscore_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"roc_auc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"f1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"precision\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"recall\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_cv_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-95-b1788c547b38>\u001b[0m in \u001b[0;36mplot_cv_score\u001b[1;34m(X, y, models_list, cv, scoring_list, refit, return_scores)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscore_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1408\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    760\u001b[0m                 \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"iprint\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gtol\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"maxiter\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             )\n\u001b[1;32m--> 762\u001b[1;33m             n_iter_i = _check_optimize_result(\n\u001b[0m\u001b[0;32m    763\u001b[0m                 \u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m                 extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py\u001b[0m in \u001b[0;36m_check_optimize_result\u001b[1;34m(solver, result, max_iter, extra_warning_msg)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[1;34m\"    https://scikit-learn.org/stable/modules/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;34m\"preprocessing.html\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             ).format(solver, result.status, result.message.decode(\"latin1\"))\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_warning_msg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0mwarning_msg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextra_warning_msg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classificadores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# um classificador linear que utiliza o Gradiente Descendente Estocástico como método de treino. \r\n",
    "# Por padrão, utiliza o estimador SVM.\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "# Uma rede neural Perceptron Multicamadas\r\n",
    "from sklearn.neural_network import MLPClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classificadores = {\r\n",
    "    'SVM': SGDClassifier(loss='hinge', penalty='l2',\r\n",
    "                           alpha=1e-3, random_state=42,\r\n",
    "                           max_iter=5, tol=None),\r\n",
    "    'SGD': SGDClassifier(max_iter=5),\r\n",
    "    'Perceptron': Perceptron(),\r\n",
    "    'NB Multinomial': MultinomialNB(alpha=0.01),\r\n",
    "    'Passive-Aggressive': PassiveAggressiveClassifier()\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cls_stats = {}\r\n",
    "for cls_name in classificadores:\r\n",
    "    stats = {'n_train': 0, 'n_train_pos': 0,\r\n",
    "             'accuracy': 0.0, 'accuracy_history': [(0, 0)], 't0': time.time(),\r\n",
    "             'runtime_history': [(0, 0)], 'total_fit_time': 0.0}\r\n",
    "    cls_stats[cls_name] = stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "total_vect_time = 0\r\n",
    "for cls_name, cls in classificadores.items():\r\n",
    "\ttick = time.time()\r\n",
    "\r\n",
    "\tppl = Pipeline([\r\n",
    "     ('vect', CountVectorizer()),\r\n",
    "     ('tfidf', TfidfTransformer()),\r\n",
    "     ('clf', cls),\r\n",
    "\t ])\r\n",
    "\t\r\n",
    "\tprint (cls_name)\r\n",
    "\tppl.fit(X_train, y_train.values.ravel())\r\n",
    "\r\n",
    "\t# accumulate test accuracy stats\r\n",
    "\tcls_stats[cls_name]['total_fit_time'] = time.time() - tick\r\n",
    "\tcls_stats[cls_name]['n_train'] = X_train.shape[0]\r\n",
    "\t#cls_stats[cls_name]['n_train_pos'] += sum(y_train)\r\n",
    "\ttick = time.time()\r\n",
    "\tcls_stats[cls_name]['accuracy'] = cls.score(X_test, y_test) \r\n",
    "\tcls_stats[cls_name]['prediction_time'] = time.time() - tick\r\n",
    "\tacc_history = (cls_stats[cls_name]['accuracy'], cls_stats[cls_name]['n_train'])\r\n",
    "\tcls_stats[cls_name]['accuracy_history'].append(acc_history)\r\n",
    "\trun_history = (cls_stats[cls_name]['accuracy'], total_vect_time + cls_stats[cls_name]['total_fit_time'])\r\n",
    "\tcls_stats[cls_name]['runtime_history'].append(run_history)\r\n",
    "\r\n",
    "\tprint (cls_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Out of Core"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\r\n",
    "from sklearn.linear_model import Perceptron\r\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\r\n",
    "import itertools"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vectorizer = HashingVectorizer(decode_error='ignore', n_features=2 ** 18,\r\n",
    "                               alternate_sign=False)\r\n",
    "\r\n",
    "\r\n",
    "# We learn a binary classification between the \"acq\" class and all the others.\r\n",
    "# \"acq\" was chosen as it is more or less evenly distributed in the Reuters\r\n",
    "# files. For other datasets, one should take care of creating a test set with\r\n",
    "# a realistic portion of positive instances.\r\n",
    "#all_classes = np.array([0, 1])\r\n",
    "#positive_class = 'acq'\r\n",
    "all_classes = y_nomes\r\n",
    "\r\n",
    "# Here are some classifiers that support the `partial_fit` method\r\n",
    "partial_fit_classifiers = {\r\n",
    "    'SGD': SGDClassifier(max_iter=5),\r\n",
    "    'Perceptron': Perceptron(),\r\n",
    "    'NB Multinomial': MultinomialNB(alpha=0.01),\r\n",
    "    'Passive-Aggressive': PassiveAggressiveClassifier(),\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_minibatch(doc_iter, size): #, pos_class=positive_class):\r\n",
    "    \"\"\"Extract a minibatch of examples, return a tuple X_text, y.\r\n",
    "\r\n",
    "    Note: size is before excluding invalid docs with no topics assigned.\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    #data = [('{title}\\n\\n{body}'.format(**doc), pos_class in doc['topics'])\r\n",
    "    #        for doc in itertools.islice(doc_iter, size)\r\n",
    "    #        if doc['topics']]\r\n",
    "    # NovaDescricao Classificacao\r\n",
    "    \r\n",
    "    data = doc_iter.iloc[:size,:]\r\n",
    "\r\n",
    "    #if not len(data):\r\n",
    "    #    return np.asarray([], dtype=int), np.asarray([], dtype=int)\r\n",
    "    X_text = data['NovaDescricao'] \r\n",
    "    y = data['Categoria']\r\n",
    "    return X_text, np.asarray(y) #, dtype=int)\r\n",
    "\r\n",
    "def iter_minibatches(doc_iter, minibatch_size):\r\n",
    "    \"\"\"Generator of minibatches.\"\"\"\r\n",
    "    X_text, y = get_minibatch(doc_iter, minibatch_size)\r\n",
    "    while len(X_text):\r\n",
    "        yield X_text, y\r\n",
    "        X_text, y = get_minibatch(doc_iter, minibatch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test data statistics\r\n",
    "test_stats = {'n_test': 0, 'n_test_pos': 0}\r\n",
    "\r\n",
    "# First we hold out a number of examples to estimate accuracy\r\n",
    "n_test_documents = 1000\r\n",
    "tick = time.time()\r\n",
    "X_test_text, y_test = get_minibatch(dfAjustado, 1000)\r\n",
    "parsing_time = time.time() - tick\r\n",
    "tick = time.time()\r\n",
    "X_test = vectorizer.transform(X_test_text)\r\n",
    "vectorizing_time = time.time() - tick\r\n",
    "test_stats['n_test'] += len(y_test)\r\n",
    "#test_stats['n_test_pos'] += sum(y_test)\r\n",
    "#print(\"Test set is %d documents (%d positive)\" % (len(y_test), sum(y_test)))\r\n",
    "print(\"Test set is %d documents\" % (len(y_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def progress(cls_name, stats):\r\n",
    "    \"\"\"Report progress information, return a string.\"\"\"\r\n",
    "    duration = time.time() - stats['t0']\r\n",
    "    s = \"%20s classifier : \\t\" % cls_name\r\n",
    "    s += \"%(n_train)6d train docs (%(n_train_pos)6d positive) \" % stats\r\n",
    "    s += \"%(n_test)6d test docs (%(n_test_pos)6d positive) \" % test_stats\r\n",
    "    s += \"accuracy: %(accuracy).3f \" % stats\r\n",
    "    s += \"in %.2fs (%5d docs/s)\" % (duration, stats['n_train'] / duration)\r\n",
    "    return s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "cls_stats = {}\r\n",
    "\r\n",
    "for cls_name in partial_fit_classifiers:\r\n",
    "    stats = {'n_train': 0, 'n_train_pos': 0,\r\n",
    "             'accuracy': 0.0, 'accuracy_history': [(0, 0)], 't0': time.time(),\r\n",
    "             'runtime_history': [(0, 0)], 'total_fit_time': 0.0}\r\n",
    "    cls_stats[cls_name] = stats\r\n",
    "\r\n",
    "get_minibatch(dfAjustado, n_test_documents)\r\n",
    "# Discard test set\r\n",
    "\r\n",
    "# We will feed the classifier with mini-batches of 1000 documents; this means\r\n",
    "# we have at most 1000 docs in memory at any time.  The smaller the document\r\n",
    "# batch, the bigger the relative overhead of the partial fit methods.\r\n",
    "minibatch_size = 1000\r\n",
    "\r\n",
    "# Create the data_stream that parses Reuters SGML files and iterates on\r\n",
    "# documents as a stream.\r\n",
    "minibatch_iterators = iter_minibatches(dfAjustado, minibatch_size)\r\n",
    "total_vect_time = 0.0\r\n",
    "\r\n",
    "# Main loop : iterate on mini-batches of examples\r\n",
    "for i, (X_train_text, y_train) in enumerate(minibatch_iterators):\r\n",
    "\r\n",
    "    tick = time.time()\r\n",
    "    X_train = vectorizer.transform(X_train_text)\r\n",
    "    total_vect_time += time.time() - tick\r\n",
    "\r\n",
    "    for cls_name, cls in partial_fit_classifiers.items():\r\n",
    "        tick = time.time()\r\n",
    "        # update estimator with examples in the current mini-batch\r\n",
    "        cls.partial_fit(X_train, y_train, classes=all_classes)\r\n",
    "\r\n",
    "        # accumulate test accuracy stats\r\n",
    "        cls_stats[cls_name]['total_fit_time'] += time.time() - tick\r\n",
    "        cls_stats[cls_name]['n_train'] += X_train.shape[0]\r\n",
    "        #cls_stats[cls_name]['n_train_pos'] += sum(y_train)\r\n",
    "        tick = time.time()\r\n",
    "        cls_stats[cls_name]['accuracy'] = cls.score(X_test, y_test)\r\n",
    "        cls_stats[cls_name]['prediction_time'] = time.time() - tick\r\n",
    "        acc_history = (cls_stats[cls_name]['accuracy'],\r\n",
    "                       cls_stats[cls_name]['n_train'])\r\n",
    "        cls_stats[cls_name]['accuracy_history'].append(acc_history)\r\n",
    "        run_history = (cls_stats[cls_name]['accuracy'],\r\n",
    "                       total_vect_time + cls_stats[cls_name]['total_fit_time'])\r\n",
    "        cls_stats[cls_name]['runtime_history'].append(run_history)\r\n",
    "\r\n",
    "        if i % 3 == 0:\r\n",
    "            print(progress(cls_name, cls_stats[cls_name]))\r\n",
    "    if i % 3 == 0:\r\n",
    "        print('\\n')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}