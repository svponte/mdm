{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mineração de Dados Massivos\r\n",
    "## Analise de descrição de mercadorias de Notas Fiscais Eletrônicas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bibliotecas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Iniciando Ambiente\r\n",
    "import numpy as np, pandas as pd, time, random\r\n",
    "import datetime as dt\r\n",
    "import re \r\n",
    "\r\n",
    "import nltk\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import unicodedata\r\n",
    "\r\n",
    "\r\n",
    "# Se necessário, descomente as linhas a seguir para ler as stopwords\r\n",
    "nltk.download('stopwords')\r\n",
    "\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Módulos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Módulos de código de programação\r\n",
    "#!pip install import-ipynb\r\n",
    "import import_ipynb\r\n",
    "# Carga de Arquivos\r\n",
    "from carga import doCarga\r\n",
    "# Tratamento de Dados         \r\n",
    "from tratamento import doTratamento\r\n",
    "# Processamento Naive Bayers\r\n",
    "#from naivebayers import doNaiveBayers\r\n",
    "\r\n",
    "from MLPClassifier import *\r\n",
    "from SGDClassifier import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Contador de tempo\r\n",
    "def tic():\r\n",
    "    global _start_time \r\n",
    "    _start_time = time.time()\r\n",
    "\r\n",
    "def tac():\r\n",
    "    t_sec = round(time.time() - _start_time)\r\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\r\n",
    "    (t_hour,t_min) = divmod(t_min,60) \r\n",
    "    print('Duração: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variáveis de Ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Pasta aonde estão os dados\r\n",
    "diretorio = '..\\\\dados\\\\'\r\n",
    "#diretorio = \"F:\\\\Weisner\\\\Documentos\\\\MEGA Estudos\\\\UNB - MDM - Mineração de Dados Massivos\\\\Artigo\\\\\" \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Abre arquivo de dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Carrega os dados\r\n",
    "dfNotas = doCarga(diretorio, opcao=3)\r\n",
    "print (\"{} registros carregados\".format(dfNotas.size))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Processa se necessário"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Chama processamento manualmente\r\n",
    "\r\n",
    "#df_original = doTratamento(df_original)\r\n",
    "#df_original.NovaDescricao\r\n",
    "#df_original.info()\r\n",
    "#tac()\r\n",
    "dfNotas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Amostsra dos Dados processados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "dfNotas['Categoria'].value_counts().plot.bar()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#print (doNaiveBayers(dfNotas))\r\n",
    "dfNotas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Análise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import warnings\r\n",
    "from pylab import rcParams\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import precision_score, recall_score\r\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\r\n",
    "from sklearn.model_selection import train_test_split\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "rcParams['figure.figsize'] = 10,6\r\n",
    "#warnings.filterwarnings('ignore')\r\n",
    "sns.set(style='darkgrid')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preleção\r\n",
    "Preparação dos datasets utilizado em todos algorítimos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Separa os contadores\r\n",
    "count_class_0, count_class_1, count_class_2, count_class_3, count_class_4 = dfNotas['Categoria'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Divide datasets por classes\r\n",
    "\r\n",
    "df_class_0 = dfNotas[dfNotas['Categoria'] == \"31.0simsim\"]\r\n",
    "df_class_1 = dfNotas[dfNotas['Categoria'] == \"38.0simsim\"]\r\n",
    "df_class_2 = dfNotas[dfNotas['Categoria'] == \"38.0simnão\"] \r\n",
    "df_class_3 = dfNotas[dfNotas['Categoria'] == \"30.0simsim\"]         # Tamanho escolhido\r\n",
    "df_class_4 = dfNotas[dfNotas['Categoria'] == \"31.0nãonão\"]         # Classse MUITO pequena - UNDERSAMPLING\r\n",
    "\r\n",
    "# Equipara os tamanhos 30.0simsim que tem 3090 ocorrências\r\n",
    "# Foram equiparados ao tamanho da classe 3\r\n",
    "MaxSize = df_class_3.size \r\n",
    "df_class_0 = df_class_0.sample(MaxSize)\r\n",
    "df_class_1 = df_class_1.sample(MaxSize)\r\n",
    "df_class_2 = df_class_2.sample(MaxSize)\r\n",
    "\r\n",
    "# Random Oversampling\r\n",
    "df_class_4 = df_class_4.sample(MaxSize, replace=True)\r\n",
    "\r\n",
    "# Agrupa novamente\r\n",
    "dfAjustado = pd.concat([df_class_0, df_class_1, df_class_2, df_class_3, df_class_4], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  Separar Dados de Atributos\r\n",
    "X = dfAjustado.iloc[:, 1:2].values  # Categoria\r\n",
    "y = dfAjustado.iloc[:, 2:3].values  # NovaDescricao"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "type(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Recorta os datasets de treinamento e teste\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorítimos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naives"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#W\r\n",
    "import sklearn\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# W\r\n",
    "\r\n",
    "Result = sklearn.model_selection.cross_val_score(text_clf, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print (Result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# T\r\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.pipeline import make_pipeline\r\n",
    "\r\n",
    "# Cria o modelo baseado no Multinomial Naive_Bayes\r\n",
    "model = make_pipeline(TfidfTransformer, MultinomialNB)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#T\r\n",
    "# Treina o modelo com o dados de treinamento\r\n",
    "result = model.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#J\r\n",
    "classificador = nltk.NaiveBayesClassifier.train(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Avaliação"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}